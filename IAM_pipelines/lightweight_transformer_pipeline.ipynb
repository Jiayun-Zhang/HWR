{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lightweight Transformer-based Model for Handwritten Character Recognition \n",
    "(https://hal.science/hal-03685976/file/A_Light_Transformer_Based_Architecture_for_Handwritten_Text_Recognition.pdf)\n",
    "\n",
    "## ***note: Has a CNN backbone***\n",
    "\n",
    "-----------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture  \n",
    "Build up with a double Transformer architecture:  \n",
    "- Image transformer as encoder: Extracts the visual features\n",
    "- Text transformer as decoder: Language modeling, generates word-sections\n",
    "             sequence using visual features and previous predictions\n",
    "\n",
    "### Encoder:  \n",
    "- CNN Backbone (5 convolutions)\n",
    "- Sinusodial position encoding  \n",
    "- 4 layer transformer layer encoder\n",
    "\n",
    "### Decoder: \n",
    "- Takes encoder output and along with sequence of previously predicted characters\n",
    "- Additional loss in the middle of the network to help convergence\n",
    "\n",
    "### Hybrid loss:\n",
    "- CTC and CE Loss combined, CTC on intermediate encoder output, CE on decoder output\n",
    "\n",
    "--------------\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "from collections import OrderedDict, Counter\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision as tv\n",
    "from torchvision.io import read_image\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/usr/bin/python3'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.executable"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = f\"/home/hkolstee/uniprojects/DATA/HWR/IAM-data/IAM-data/\"\n",
    "TRAIN_TEST_SPLIT = 0.2\n",
    "BATCH_SIZE = 16\n",
    "INPUT_HEIGHT = 128\n",
    "# input width -> largest width in batch\n",
    "#   images max resized and subsequently padded to get to width\n",
    "EPOCHS = 500"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_names</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a03-017-07.png</td>\n",
       "      <td>into the pro-communist north and the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a03-017-05.png</td>\n",
       "      <td>to 1958 kept the kingdom in peace, though</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a03-017-08.png</td>\n",
       "      <td>pro-western centre and south.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a03-017-02.png</td>\n",
       "      <td>in Phnom Penh indicate that he still regards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a03-017-06.png</td>\n",
       "      <td>at the cost of virtual partition of the country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7453</th>\n",
       "      <td>d06-000-08.png</td>\n",
       "      <td>fears are based upon completely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7454</th>\n",
       "      <td>d06-000-05.png</td>\n",
       "      <td>is worrying them, to find the original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7455</th>\n",
       "      <td>d06-000-09.png</td>\n",
       "      <td>irrational pre-conceived notions - or to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7456</th>\n",
       "      <td>d06-000-02.png</td>\n",
       "      <td>already suggested, not to be silly or</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7457</th>\n",
       "      <td>d06-000-00.png</td>\n",
       "      <td>In the first place it is not a great deal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7458 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           img_names                                           labels\n",
       "0     a03-017-07.png             into the pro-communist north and the\n",
       "1     a03-017-05.png        to 1958 kept the kingdom in peace, though\n",
       "2     a03-017-08.png                    pro-western centre and south.\n",
       "3     a03-017-02.png     in Phnom Penh indicate that he still regards\n",
       "4     a03-017-06.png  at the cost of virtual partition of the country\n",
       "...              ...                                              ...\n",
       "7453  d06-000-08.png                  fears are based upon completely\n",
       "7454  d06-000-05.png           is worrying them, to find the original\n",
       "7455  d06-000-09.png         irrational pre-conceived notions - or to\n",
       "7456  d06-000-02.png            already suggested, not to be silly or\n",
       "7457  d06-000-00.png        In the first place it is not a great deal\n",
       "\n",
       "[7458 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.read_fwf(DATA_PATH + \"iam_lines_gt.txt\", header = None)\n",
    "raw_data = raw_data.values.tolist()\n",
    "\n",
    "data = {'img_names': np.squeeze(raw_data[::2]),\n",
    "        'labels': np.squeeze(raw_data[1::2])}\n",
    "\n",
    "data = pd.DataFrame(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "an Italian who is perhaps the best Valet de Chambre\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd625c90220>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# example\n",
    "ex_label = \"an Italian who is perhaps the best Valet de Chambre\" \n",
    "print(ex_label)\n",
    "# print(data['labels'][0])\n",
    "image = read_image(os.path.join(DATA_PATH, \"img\", \"g06-026i-01.png\"))\n",
    "plt.imshow(image[0, :, :], cmap = \"gray\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first, we need the input/image width we have to resize the images to.  \n",
    "This is the largest image width in the entire batch of images (source paper randomly added/removed new augments each training epoch).   \n",
    "For now we just take the largest width in the original images.  \n",
    "  \n",
    "The labels are later padded to the largest label size in the dataset, such that we also need to know the longest label size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBiggestWidth(data: pd.DataFrame):\n",
    "    biggest_width = 0\n",
    "\n",
    "    for index in range(len(data['img_names'])):\n",
    "        image_path = os.path.join(DATA_PATH, \"img\", data['img_names'][index])\n",
    "        image = read_image(image_path)\n",
    "        \n",
    "        if (image.size(2) > biggest_width):\n",
    "            biggest_width = image.size(2)\n",
    "\n",
    "    return biggest_width\n",
    "\n",
    "def getLongestLabel(data: pd.DataFrame):\n",
    "    longest = 0\n",
    "    \n",
    "    for index in range(len(data['labels'])):\n",
    "        if (len(data['labels'][index]) > longest):\n",
    "            longest = len(data['labels'][index])\n",
    "            \n",
    "    return longest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Biggest width needed to pad all images to this width for the input into the encoder.  \n",
    "Longest label needed to pad all labels to this length for the input into the decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2260\n",
      "56\n"
     ]
    }
   ],
   "source": [
    "input_width = getBiggestWidth(data)\n",
    "print(input_width)\n",
    "\n",
    "longest_label = getLongestLabel(data)\n",
    "# <BOS> and <EOS> tokens not counted\n",
    "longest_label += 2\n",
    "print(longest_label)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Data augmentation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resize and pad images to largest width in dataset  \n",
    "### ***NOTE: Not sure if padding should be all at the right part of the image or both sides***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resizes to largest width in batch x 128, keeping aspect ratio and padding image\n",
    "class resizeImage(object):\n",
    "    def __init__(self, resize_width, resize_height):\n",
    "        self.resize_width = resize_width\n",
    "        self.resize_height = resize_height\n",
    "    \n",
    "    def __call__(self, image):\n",
    "        # check if resizing to correct height while keeping aspect ratio does not overshoot correct width\n",
    "        aspect_ratio_width = int((self.resize_height / image.size(1)) * image.size(2))\n",
    "        if (aspect_ratio_width > self.resize_width):\n",
    "            # calculate max ratio of change for not overshooting resize width while keeping aspect ratio \n",
    "            max_ratio = self.resize_width / image.size(2)\n",
    "            max_resize_height = int(max_ratio * image.size(1))\n",
    "            # calc up and down padding\n",
    "            padding_up = int(((self.resize_height - max_resize_height) / 2))\n",
    "            padding_down = self.resize_height - max_resize_height - padding_up\n",
    "            # change resize height to max calculated resize height\n",
    "            new_resize_height = max_resize_height\n",
    "        else:\n",
    "            padding_up = 0\n",
    "            padding_down = 0\n",
    "            new_resize_height = self.resize_height\n",
    "\n",
    "        # resize to correct image height, while keeping aspect ratio\n",
    "        resize_transform = tv.transforms.Resize((new_resize_height, self.resize_width), antialias = True)\n",
    "        resized = resize_transform(image)\n",
    "        \n",
    "        # pad to correct width (and height if necessary)\n",
    "        padding_left = int(((self.resize_width - resized.size(2)) / 2))\n",
    "        padding_right = self.resize_width - resized.size(2) - padding_left\n",
    "        resized_padded = F.pad(resized, (padding_left, padding_right, padding_up, padding_down), mode = \"constant\", value = 255)\n",
    "\n",
    "        return resized_padded"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This example because it previously overshot the correct width using the height measurements for the aspect ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "an Italian who is perhaps the best Valet de Chambre\n",
      "torch.Size([1, 86, 1758])\n",
      "torch.Size([1, 128, 2260])\n",
      "torch.uint8\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(ex_label)\n",
    "image = read_image(os.path.join(DATA_PATH, \"img\", \"g06-026i-01.png\"))\n",
    "print(image.shape)\n",
    "\n",
    "resize_transform = resizeImage(input_width, INPUT_HEIGHT)\n",
    "resized_image = resize_transform(image)\n",
    "plt.imshow(resized_image[0, :, :], cmap = \"gray\")\n",
    "print(resized_image.shape)\n",
    "print(resized_image.dtype)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resize and pad for the whole dataset and save in a new dir such that we don't have to do this each epoch. TODO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size = TRAIN_TEST_SPLIT)\n",
    "\n",
    "# reset indices from current random state\n",
    "train.reset_index(inplace = True)\n",
    "test.reset_index(inplace = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create custom pytorch dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For character level embedding (decoder input) we find out how many characters are present in the dataset. By counting the characters we give the most common characters the lowest indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a dict of uniques chars sorted on how common they are in the dataset labels\n",
    "def uniqueCharsByMostCommon(data: pd.DataFrame):\n",
    "    sortedDict = OrderedDict(Counter(''.join(data['labels'].values)).most_common())\n",
    "    newDict = {}\n",
    "    \n",
    "    # first add pad, begin of sentence, and end of sentence tokens\n",
    "    newDict[\"<PAD>\"] = 0\n",
    "    newDict[\"<BOS>\"] = 1\n",
    "    newDict[\"<EOS>\"] = 2\n",
    "    \n",
    "    for idx, char in enumerate(sortedDict):\n",
    "        newDict[char] = idx + 3\n",
    "    \n",
    "    return newDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<PAD>': 0,\n",
       " '<BOS>': 1,\n",
       " '<EOS>': 2,\n",
       " ' ': 3,\n",
       " 'e': 4,\n",
       " 't': 5,\n",
       " 'a': 6,\n",
       " 'o': 7,\n",
       " 'n': 8,\n",
       " 'i': 9,\n",
       " 's': 10,\n",
       " 'r': 11,\n",
       " 'h': 12,\n",
       " 'l': 13,\n",
       " 'd': 14,\n",
       " 'c': 15,\n",
       " 'u': 16,\n",
       " 'm': 17,\n",
       " 'f': 18,\n",
       " 'p': 19,\n",
       " 'w': 20,\n",
       " 'g': 21,\n",
       " 'y': 22,\n",
       " 'b': 23,\n",
       " '.': 24,\n",
       " ',': 25,\n",
       " 'v': 26,\n",
       " 'k': 27,\n",
       " \"'\": 28,\n",
       " '\"': 29,\n",
       " '-': 30,\n",
       " 'T': 31,\n",
       " 'I': 32,\n",
       " 'M': 33,\n",
       " 'A': 34,\n",
       " 'S': 35,\n",
       " 'B': 36,\n",
       " 'P': 37,\n",
       " 'H': 38,\n",
       " 'W': 39,\n",
       " 'C': 40,\n",
       " 'N': 41,\n",
       " 'G': 42,\n",
       " 'x': 43,\n",
       " 'R': 44,\n",
       " 'L': 45,\n",
       " 'E': 46,\n",
       " 'D': 47,\n",
       " 'F': 48,\n",
       " '0': 49,\n",
       " '1': 50,\n",
       " 'j': 51,\n",
       " 'O': 52,\n",
       " 'q': 53,\n",
       " '!': 54,\n",
       " 'U': 55,\n",
       " '(': 56,\n",
       " 'K': 57,\n",
       " '?': 58,\n",
       " 'z': 59,\n",
       " '3': 60,\n",
       " ')': 61,\n",
       " '9': 62,\n",
       " ';': 63,\n",
       " 'V': 64,\n",
       " '2': 65,\n",
       " 'J': 66,\n",
       " 'Y': 67,\n",
       " ':': 68,\n",
       " '5': 69,\n",
       " '8': 70,\n",
       " '4': 71,\n",
       " '6': 72,\n",
       " '#': 73,\n",
       " '&': 74,\n",
       " '7': 75,\n",
       " '/': 76,\n",
       " 'Q': 77,\n",
       " 'X': 78,\n",
       " '*': 79,\n",
       " 'Z': 80,\n",
       " '+': 81}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get mapping before splitting dataset\n",
    "char_to_idx_mapping = uniqueCharsByMostCommon(data)\n",
    "char_to_idx_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HandWritingDataset(Dataset):\n",
    "    def __init__(self, data: pd.DataFrame, data_path, img_width, img_height, char_to_idx_mapping: dict, max_label_size):\n",
    "        self.data = data\n",
    "        self.data_path = data_path\n",
    "        self.img_width = img_width\n",
    "        self.img_height = img_height\n",
    "        self.label_size = max_label_size\n",
    "\n",
    "        self.char_to_idx_mapping = char_to_idx_mapping\n",
    "        self.idx_to_char_mapping = {value: key for key, value in self.char_to_idx_mapping.items()}\n",
    "\n",
    "        self.createLabelEncodings()\n",
    "        # self.reshapeAndStoreImages()\n",
    "\n",
    "        # calc mean and std of images combines for standardization\n",
    "        mean, std = self.calcImagesMeanStd()\n",
    "\n",
    "        # composed transform\n",
    "        self.transforms = tv.transforms.Compose([resizeImage(img_width, img_height),\n",
    "                                                tv.transforms.Normalize(mean, std)])\n",
    "\n",
    "\n",
    "    def createLabelEncodings(self):\n",
    "        # change character level strings to embed indices \n",
    "        #   (embedding itself calculated in forward pass)\n",
    "        self.labels_as_idxs = [torch.tensor([[self.char_to_idx_mapping[char]] for char in label]) for label in data['labels']]   \n",
    "        # add <EOS> tokens at the end of sentences\n",
    "        self.labels_as_idxs = [torch.cat([label, torch.tensor([[self.char_to_idx_mapping['<EOS>']]])]) for label in self.labels_as_idxs]\n",
    "        # input into decoder shifted right (while training) and <BOS> token inserted at start\n",
    "        self.decoder_input_as_idxs = [torch.cat([torch.tensor([[self.char_to_idx_mapping['<BOS>']]]), label]) for label in self.labels_as_idxs]\n",
    "        \n",
    "        # pad labels embedding indices to largest label length with <PAD> token\n",
    "        self.labels_as_idxs = [F.pad(label, (0, 0, 0, self.label_size - label.shape[0]), mode = 'constant', value = self.char_to_idx_mapping['<PAD>']) \\\n",
    "                               for label in self.labels_as_idxs]\n",
    "        \n",
    "        # pad decoder input char embedding indices to largest label length with <PAD> tokens \n",
    "        self.decoder_input_as_idxs = [F.pad(label, (0, 0, 0, self.label_size - label.shape[0]), mode = 'constant', value = self.char_to_idx_mapping['<PAD>']) \\\n",
    "                               for label in self.decoder_input_as_idxs]\n",
    "        \n",
    "        # transform target labels into one hot encoding vectors\n",
    "        self.labels_as_onehot =  [F.one_hot(label, num_classes = len(self.char_to_idx_mapping)) for label in self.labels_as_idxs]        \n",
    "\n",
    "    # reshapes + pads the images to the correct input width and height\n",
    "    # def reshapeAndStoreImages(self):\n",
    "    #     self.images = []\n",
    "\n",
    "    #     for image_name in self.data['img_names']:\n",
    "    #         # read image\n",
    "    #         image = read_image(os.path.join(self.data_path, \"img\", image_name))\n",
    "    #         # resize + pad image to correct input size\n",
    "    #         resized_padded = resizeImage(image, self.img_width, self.img_height)\n",
    "    #         # store in list of tensors\n",
    "    #         self.images.append(resized_padded)\n",
    "\n",
    "            \n",
    "    # Function to calc the mean and std of a dataset to use in image standardization \n",
    "    def calcImagesMeanStd(self):\n",
    "        running_mean = 0\n",
    "        running_std = 0\n",
    "\n",
    "        for image_name in self.data['img_names']:\n",
    "            image = read_image(os.path.join(self.data_path, \"img\", image_name))\n",
    "\n",
    "            mean = torch.mean(image.float())\n",
    "            std = torch.std(image.float())\n",
    "\n",
    "            running_mean += mean\n",
    "            running_std += std\n",
    "\n",
    "        return (running_mean / len(self.data)), (running_std / len(self.data))\n",
    "    \n",
    "    # transforms done in __getitem__ so that images can be stored as Byte tensors (-> less memory and kernel does not crash)\n",
    "    def __getitem__(self, index):\n",
    "        # image\n",
    "        # image = self.images[index].float()\n",
    "        image = read_image(os.path.join(self.data_path, \"img\", self.data['img_names'][index])).float()\n",
    "        # transform image (resize/pas + normalize)\n",
    "        image = self.transforms(image)\n",
    "        # paper adds gaussian noise to image (sqrt(0.1) * rand from gaussian distri)\n",
    "        #   TODO: add to transforms for cleaner code\n",
    "        image += ((0.1**0.5) * torch.randn(image.shape)) * 0.75\n",
    "\n",
    "        # label\n",
    "        label = self.labels_as_onehot[index]\n",
    "        # label shifted right\n",
    "        decoder_in = self.decoder_input_as_idxs[index]\n",
    "\n",
    "        # image = tensor, label = one hot encoded target characters, decoder_in = label shifted right as indices for embedding table\n",
    "        return image, label, decoder_in\n",
    "\n",
    "    def __len__(self):\n",
    "        # return length of column\n",
    "        return len(self.data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create datasets and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets\n",
    "train_set = HandWritingDataset(train, DATA_PATH, input_width, INPUT_HEIGHT, char_to_idx_mapping, longest_label)\n",
    "test_set = HandWritingDataset(test, DATA_PATH, input_width, INPUT_HEIGHT, char_to_idx_mapping, longest_label)\n",
    "\n",
    "# dataloaders\n",
    "train_loader = DataLoader(train_set, batch_size = BATCH_SIZE, shuffle = True)\n",
    "test_loader = DataLoader(test_set, batch_size = BATCH_SIZE, shuffle = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sinusodial positional encoding  \n",
    "(can be changed to nn.embedding layers if we don't get good results, however that is not exactly sinusodial pos encoding like in the paper I think)\n",
    "\n",
    "<!-- **CHANGED TO NN.EMBEDDING IN MODEL**   -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinPosEncoding(nn.Module):\n",
    "    def __init__(self, dimensionality):\n",
    "        super(SinPosEncoding, self).__init__()\n",
    "        self.dims = dimensionality\n",
    "        self.max_len = 1000\n",
    "\n",
    "        # position vector\n",
    "        positions = torch.arange(0, self.max_len).unsqueeze(1)\n",
    "        # calculate added angle for sin/cos\n",
    "        angle = torch.exp(torch.arange(0, self.dims, 1) * (-np.log(10000.0) / self.dims))\n",
    "\n",
    "        # initialize the 2D positional encodings array\n",
    "        pos_encodings = torch.zeros(self.max_len, 1, self.dims)\n",
    "        # calucalte encodings\n",
    "        pos_encodings[:, 0, :] = torch.sin(positions * angle)\n",
    "\n",
    "        # add to buffer for training performance (?)\n",
    "        self.register_buffer('pos_encodings', pos_encodings)\n",
    "\n",
    "    \n",
    "    def forward(self, input: torch.Tensor):\n",
    "        # print(\"\\n\", input.shape)\n",
    "        # print(self.pos_encodings.shape)\n",
    "        # print(self.pos_encodings[0:input.size(0)].shape)\n",
    "        # adds the positional encoding elementwise to the tensor (seqlength, batch, embeddims)\n",
    "        input += self.pos_encodings[0:input.size(0)]\n",
    "        # print(\"succes\\n\")\n",
    "\n",
    "        return input"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_height, input_width):\n",
    "        super(CNN, self).__init__()\n",
    "        # convolutional block (5 convolutions)\n",
    "        # first convolution\n",
    "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 8, kernel_size = (3,3))\n",
    "        width = input_width - 2\n",
    "        height = input_height - 2\n",
    "        self.leakyRelu = nn.LeakyReLU()     # reuse in later layers\n",
    "        self.maxPool = nn.MaxPool2d((2,2))  # reuse in later layers\n",
    "        width = int(np.floor(width/2))\n",
    "        height = int(np.floor(height/2))\n",
    "        self.layerNorm1 = nn.LayerNorm(normalized_shape = [8, height, width])\n",
    "        self.dropout = nn.Dropout(0.2)      # reuse in later layers\n",
    "\n",
    "        # second convolutional layer\n",
    "        self.conv2 = nn.Conv2d(in_channels = 8, out_channels = 16, kernel_size = (3, 3))\n",
    "        width -= 2\n",
    "        height -= 2\n",
    "        # after maxpool\n",
    "        width = int(np.floor(width/2))\n",
    "        height = int(np.floor(height/2))\n",
    "        self.layerNorm2 = nn.LayerNorm(normalized_shape = [16, height, width])\n",
    "\n",
    "        # third convolutional layer\n",
    "        self.conv3 = nn.Conv2d(in_channels = 16, out_channels = 32, kernel_size = (3, 3))\n",
    "        width -= 2\n",
    "        height -= 2\n",
    "        # after maxpool\n",
    "        width = int(np.floor(width/2))\n",
    "        height = int(np.floor(height/2))\n",
    "        self.layerNorm3 = nn.LayerNorm(normalized_shape = [32, height, width])\n",
    "\n",
    "        # forth convolutional layer\n",
    "        self.conv4 = nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = (3, 3))\n",
    "        width -= 2\n",
    "        height -= 2\n",
    "        # no maxpool\n",
    "        self.layerNorm4 = nn.LayerNorm(normalized_shape = [64, height, width])\n",
    "\n",
    "        # fifth convolutional layer (kernel size to better match shape of character)\n",
    "        self.conv5 = nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size = (4, 2))\n",
    "        width -= 1\n",
    "        height -= 3\n",
    "        # no maxpool\n",
    "        self.layerNorm5 = nn.LayerNorm(normalized_shape = [128, height, width])\n",
    "\n",
    "        # following is convolution with width 1 which is used to flatten the current output\n",
    "        self.flattenConv = nn.Conv2d(in_channels = 128, out_channels = 128, kernel_size = (height, 1))\n",
    "        self.layerNorm6 = nn.LayerNorm(normalized_shape = [128, 1, width])\n",
    "\n",
    "        # dense layer to upscale from 128 to 256\n",
    "        self.dense = nn.Linear(in_features = 128, out_features = 256)\n",
    "\n",
    "    def forward(self, input_img):\n",
    "        # first conv\n",
    "        conv_out = self.layerNorm1(self.maxPool(self.leakyRelu(self.conv1(input_img))))\n",
    "        conv_out = self.dropout(conv_out)\n",
    "        # second conv\n",
    "        conv_out = self.layerNorm2(self.maxPool(self.leakyRelu(self.conv2(conv_out))))\n",
    "        conv_out = self.dropout(conv_out)\n",
    "        # third conv\n",
    "        conv_out = self.layerNorm3(self.maxPool(self.leakyRelu(self.conv3(conv_out))))\n",
    "        conv_out = self.dropout(conv_out)\n",
    "        # forth conv\n",
    "        conv_out = self.layerNorm4(self.leakyRelu(self.conv4(conv_out)))\n",
    "        # fifth conv\n",
    "        conv_out = self.layerNorm5(self.leakyRelu(self.conv5(conv_out)))\n",
    "\n",
    "        # flatten layer\n",
    "        conv_out = self.layerNorm6(self.leakyRelu(self.flattenConv(conv_out)))\n",
    "\n",
    "        # reshape from ((batch, 128, 1, x) -> (batch, x, 1, 128)) for dense layer\n",
    "        conv_out = torch.reshape(conv_out, (conv_out.size(0), conv_out.size(3), conv_out.size(2), conv_out.size(1)))\n",
    "\n",
    "        # upscale from 128 to 256\n",
    "        conv_out = self.dense(conv_out)\n",
    "\n",
    "        # reshape to (seq, batch, embed_dim)\n",
    "        conv_out = torch.reshape(conv_out, (conv_out.size(1), conv_out.size(0), conv_out.size(3)))\n",
    "        \n",
    "        return conv_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HWRTransformerEncoder(nn.Module):\n",
    "    def __init__(self, total_nr_of_tokens):\n",
    "        super(HWRTransformerEncoder, self).__init__()\n",
    "        # transformer encoder layers (4 stacked transformer encoder layers (4 headed attention))\n",
    "        self.trans_encoder1 = nn.TransformerEncoderLayer(d_model = 256, nhead = 4, dim_feedforward = 1024, dropout = 0.2)\n",
    "        self.trans_encoder2 = nn.TransformerEncoderLayer(d_model = 256, nhead = 4, dim_feedforward = 1024, dropout = 0.2)\n",
    "        self.trans_encoder3 = nn.TransformerEncoderLayer(d_model = 256, nhead = 4, dim_feedforward = 1024, dropout = 0.2)\n",
    "        self.trans_encoder4 = nn.TransformerEncoderLayer(d_model = 256, nhead = 4, dim_feedforward = 1024, dropout = 0.2)\n",
    "\n",
    "        # dense layer for backprop CTC Loss of intermediate encoder result\n",
    "        self.encoder_out_dense = nn.Linear(256, total_nr_of_tokens)\n",
    "\n",
    "    def forward(self, encoder_input):\n",
    "        # transformer encoder layers\n",
    "        encoder_out = self.trans_encoder1(encoder_input)\n",
    "        encoder_out = self.trans_encoder2(encoder_out)\n",
    "        encoder_out = self.trans_encoder3(encoder_out)\n",
    "        encoder_out = self.trans_encoder4(encoder_out)\n",
    "\n",
    "        return encoder_out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HWRTransformerDecoder(nn.Module):\n",
    "    def __init__(self, total_nr_of_tokens):\n",
    "        super(HWRTransformerDecoder, self).__init__()\n",
    "\n",
    "        # transformer decoder layers (4 stacked transformer encoder layers (4 headed attention))\n",
    "        self.trans_decoder1 = nn.TransformerDecoderLayer(d_model = 256, nhead = 4, dim_feedforward = 1024, dropout = 0.2)\n",
    "        self.trans_decoder2 = nn.TransformerDecoderLayer(d_model = 256, nhead = 4, dim_feedforward = 1024, dropout = 0.2)\n",
    "        self.trans_decoder3 = nn.TransformerDecoderLayer(d_model = 256, nhead = 4, dim_feedforward = 1024, dropout = 0.2)\n",
    "        self.trans_decoder4 = nn.TransformerDecoderLayer(d_model = 256, nhead = 4, dim_feedforward = 1024, dropout = 0.2)\n",
    "\n",
    "        self.decoder_out_dense = nn.Linear(256, total_nr_of_tokens)\n",
    "\n",
    "    def forward(self, decoder_in, encoder_out, target_mask):\n",
    "        # input encoder output and predicted chars into decoder\n",
    "        decoder_out = self.trans_decoder1(decoder_in, encoder_out, target_mask)\n",
    "        decoder_out = self.trans_decoder2(decoder_out, encoder_out, target_mask)\n",
    "        decoder_out = self.trans_decoder3(decoder_out, encoder_out, target_mask)\n",
    "        decoder_out = self.trans_decoder4(decoder_out, encoder_out, target_mask)\n",
    "\n",
    "        # dense layer after decoder to predict one of all tokens (CE Loss)\n",
    "        decoder_out = self.decoder_out_dense(decoder_out)\n",
    "\n",
    "        return decoder_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HWRTransformer(nn.Module):\n",
    "    def __init__(self, input_height, input_width, total_nr_of_tokens, longest_label_size):\n",
    "        super(HWRTransformer, self).__init__()\n",
    "        # CNN backbone to extract optical features of input image\n",
    "        self.cnn = CNN(input_height, input_width)\n",
    "\n",
    "        # pre-encoder positional information\n",
    "        self.encoder_pos_encoding = SinPosEncoding(dimensionality = 256)\n",
    "\n",
    "        # Transformer encoder\n",
    "        self.transformer_encoder = HWRTransformerEncoder(total_nr_of_tokens)\n",
    "        # dense layer for intermediate output (to backprop with CTC Loss)\n",
    "        self.encoder_out_dense = nn.Linear(256, total_nr_of_tokens)\n",
    "\n",
    "        # character embedding (dim rule of thumb -> 4th sqrt of nr_embeddings: for ~80 = 3) \n",
    "        #      NOTE: wrong, appearantly dims (encoder output, target embedding) need to be the same\n",
    "        # <PAD> embedding idx = 0\n",
    "        self.char_embedding = nn.Embedding(total_nr_of_tokens, 256, padding_idx = 0)\n",
    "\n",
    "        # Transformer decoder \n",
    "        self.decoder_target_mask = self.make_target_mask(longest_label_size)\n",
    "        self.transformer_decoder = HWRTransformerDecoder(total_nr_of_tokens)\n",
    "\n",
    "    # create a target mask for decoder input\n",
    "    #   masks the future target characters from being seen by the model before they should\n",
    "    def make_target_mask(self, size):\n",
    "        mask = torch.zeros((size, size), dtype = torch.float32)\n",
    "        \n",
    "        for i in range(size):\n",
    "            for j in range(size):\n",
    "                if (j > i):\n",
    "                    mask[i][j] = float('-inf')\n",
    "        return mask\n",
    "    \n",
    "    def forward(self, input_image, decoder_in_embed_idxs):\n",
    "        # forward through backbone convolutional neural network\n",
    "        cnn_out = self.cnn(input_image)\n",
    "\n",
    "        # add pre-encoder positional information\n",
    "        cnn_out = self.encoder_pos_encoding(cnn_out)\n",
    "        \n",
    "        # forward through transformer encoder\n",
    "        encoder_out = self.transformer_encoder(cnn_out)\n",
    "        # dense layer for intermediate output (to backprop with CTC Loss)\n",
    "        interm_encoder_out = self.encoder_out_dense(encoder_out)\n",
    "\n",
    "        # add pre-decoder positional information\n",
    "        encoder_out = self.encoder_pos_encoding(encoder_out)\n",
    "\n",
    "        # embed character indices for input into decoder\n",
    "        shifted_target = self.char_embedding(decoder_in_embed_idxs)\n",
    "        # reshape from (batch, seq_len, 1, embed_dim) -> (seq_len, batch, embed_dim)\n",
    "        shifted_target = torch.reshape(shifted_target, (shifted_target.size(1), shifted_target.size(0), shifted_target.size(3)))\n",
    "\n",
    "        # forward through transformer decoder\n",
    "        decoder_out = self.transformer_decoder(shifted_target, encoder_out, self.decoder_target_mask)\n",
    "\n",
    "        return interm_encoder_out, decoder_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class HWRTransformer(nn.Module):\n",
    "#     def __init__(self, input_width, input_height, total_nr_of_tokens, longest_label):\n",
    "#         super(HWRTransformer, self).__init__()\n",
    "#         # generate target mask for decoder (can be reused as target sequences are padded to same length (probably?))\n",
    "#         self.target_mask = self.make_target_mask(longest_label)\n",
    "\n",
    "#         # convolutional block (5 convolutions)\n",
    "#         # first convolution\n",
    "#         self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 8, kernel_size = (3,3))\n",
    "#         width = input_width - 2\n",
    "#         height = input_height - 2\n",
    "#         self.leakyRelu = nn.LeakyReLU()     # reuse in later layers\n",
    "#         self.maxPool = nn.MaxPool2d((2,2))  # reuse in later layers\n",
    "#         width = int(np.floor(width/2))\n",
    "#         height = int(np.floor(height/2))\n",
    "#         self.layerNorm1 = nn.LayerNorm(normalized_shape = [8, height, width])\n",
    "#         self.dropout = nn.Dropout(0.2)      # reuse in later layers\n",
    "\n",
    "#         # second convolutional layer\n",
    "#         self.conv2 = nn.Conv2d(in_channels = 8, out_channels = 16, kernel_size = (3, 3))\n",
    "#         width -= 2\n",
    "#         height -= 2\n",
    "#         # after maxpool\n",
    "#         width = int(np.floor(width/2))\n",
    "#         height = int(np.floor(height/2))\n",
    "#         self.layerNorm2 = nn.LayerNorm(normalized_shape = [16, height, width])\n",
    "\n",
    "\n",
    "#         # third convolutional layer\n",
    "#         self.conv3 = nn.Conv2d(in_channels = 16, out_channels = 32, kernel_size = (3, 3))\n",
    "#         width -= 2\n",
    "#         height -= 2\n",
    "#         # after maxpool\n",
    "#         width = int(np.floor(width/2))\n",
    "#         height = int(np.floor(height/2))\n",
    "#         self.layerNorm3 = nn.LayerNorm(normalized_shape = [32, height, width])\n",
    "\n",
    "#         # forth convolutional layer\n",
    "#         self.conv4 = nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = (3, 3))\n",
    "#         width -= 2\n",
    "#         height -= 2\n",
    "#         # no maxpool\n",
    "#         self.layerNorm4 = nn.LayerNorm(normalized_shape = [64, height, width])\n",
    "\n",
    "#         # fifth convolutional layer (kernel size to better match shape of character)\n",
    "#         self.conv5 = nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size = (4, 2))\n",
    "#         width -= 1\n",
    "#         height -= 3\n",
    "#         # no maxpool\n",
    "#         self.layerNorm5 = nn.LayerNorm(normalized_shape = [128, height, width])\n",
    "\n",
    "#         # following is convolution with width 1 which is used to flatten the current output\n",
    "#         self.flattenConv = nn.Conv2d(in_channels = 128, out_channels = 128, kernel_size = (height, 1))\n",
    "#         # self.layerNorm6 = nn.LayerNorm(normalized_shape = [128, 1, width])\n",
    "\n",
    "#         # dense layer to upscale from 128 to 256\n",
    "#         self.dense1 = nn.Linear(in_features = 128, out_features = 256)\n",
    "#         # sinusoidal positional encoding is added to the output of the dense layer\n",
    "#         self.encoder_pos_encoding = SinPosEncoding(dimensionality = 256)\n",
    "\n",
    "#         # transformer encoder layers (4 stacked transformer encoder layers (4 headed attention))\n",
    "#         self.trans_encoder1 = nn.TransformerEncoderLayer(d_model = 256, nhead = 4, dim_feedforward = 1024, dropout = 0.2)\n",
    "#         self.trans_encoder2 = nn.TransformerEncoderLayer(d_model = 256, nhead = 4, dim_feedforward = 1024, dropout = 0.2)\n",
    "#         self.trans_encoder3 = nn.TransformerEncoderLayer(d_model = 256, nhead = 4, dim_feedforward = 1024, dropout = 0.2)\n",
    "#         self.trans_encoder4 = nn.TransformerEncoderLayer(d_model = 256, nhead = 4, dim_feedforward = 1024, dropout = 0.2)\n",
    "\n",
    "#         # dense layer for backprop CTC Loss of intermediate encoder result\n",
    "#         self.encoder_out_dense = nn.Linear(256, total_nr_of_tokens)\n",
    "\n",
    "#         # Here starts: decoder\n",
    "#         # character embedding (dim rule of thumb -> 4th sqrt of nr_embeddings: for ~80 = 3) \n",
    "#         #      NOTE: wrong, appearantly dims (encoder output, target embedding) need to be the same\n",
    "#         # <PAD> embedding idx = 0\n",
    "#         self.char_embedding = nn.Embedding(total_nr_of_tokens, 256, padding_idx = 0)\n",
    "#         # positional embedding of decoder input sequence\n",
    "#         self.decoder_pos_encoding = SinPosEncoding(dimensionality = 256)\n",
    "\n",
    "#         # transformer decoder layers (4 stacked transformer encoder layers (4 headed attention))\n",
    "#         self.trans_decoder1 = nn.TransformerDecoderLayer(d_model = 256, nhead = 4, dim_feedforward = 1024, dropout = 0.2)\n",
    "#         self.trans_decoder2 = nn.TransformerDecoderLayer(d_model = 256, nhead = 4, dim_feedforward = 1024, dropout = 0.2)\n",
    "#         self.trans_decoder3 = nn.TransformerDecoderLayer(d_model = 256, nhead = 4, dim_feedforward = 1024, dropout = 0.2)\n",
    "#         self.trans_decoder4 = nn.TransformerDecoderLayer(d_model = 256, nhead = 4, dim_feedforward = 1024, dropout = 0.2)\n",
    "\n",
    "#         self.decoder_out_dense = nn.Linear(256, total_nr_of_tokens)\n",
    "    \n",
    "#     # create a target mask for decoder input\n",
    "#     #   masks the future target characters from being seen by the model before they should\n",
    "#     def make_target_mask(self, size):\n",
    "#         mask = torch.zeros((size, size), dtype = torch.float32)\n",
    "        \n",
    "#         for i in range(size):\n",
    "#             for j in range(size):\n",
    "#                 if (j > i):\n",
    "#                     mask[i][j] = float('-inf')\n",
    "#         return mask\n",
    "    \n",
    "#     # first forward call: interm_outputs shoudl be a tensor with the embedding of <BOS>\n",
    "#     def forward(self, input_img, decoder_in_idxs):\n",
    "#         print(input_img.shape, decoder_in_idxs.shape)\n",
    "#         # through 5 convolutional layers\n",
    "#         # first conv\n",
    "#         print(\"start forward\")\n",
    "#         conv_out = self.layerNorm1(self.maxPool(self.leakyRelu(self.conv1(input_img))))\n",
    "#         conv_out = self.dropout(conv_out)\n",
    "#         # second conv\n",
    "#         conv_out = self.layerNorm2(self.maxPool(self.leakyRelu(self.conv2(conv_out))))\n",
    "#         conv_out = self.dropout(conv_out)\n",
    "#         # third conv\n",
    "#         conv_out = self.layerNorm3(self.maxPool(self.leakyRelu(self.conv3(conv_out))))\n",
    "#         conv_out = self.dropout(conv_out)\n",
    "#         # forth conv\n",
    "#         conv_out = self.layerNorm4(self.leakyRelu(self.conv4(conv_out)))\n",
    "#         # fifth conv\n",
    "#         conv_out = self.layerNorm5(self.leakyRelu(self.conv5(conv_out)))\n",
    "\n",
    "#         # flatten layer\n",
    "#         conv_out = self.layerNorm6(self.leakyRelu(self.flattenConv(conv_out)))\n",
    "\n",
    "#         # dense layer (activation function not mentioned in paper) \n",
    "#         # needs reshaped tensor where dims are reversed ((batch, 128, 1, x) -> (batch, x, 1, 128))\n",
    "#         conv_out = torch.reshape(conv_out, (conv_out.size(0), conv_out.size(3), conv_out.size(2), conv_out.size(1)))\n",
    "#         conv_out = self.dense1(conv_out)\n",
    "\n",
    "#         print(\"conv out succes\")\n",
    "\n",
    "#         # add sinusodial positional information\n",
    "#         # needs reshape (batch, seq_len, 1, 256) -> (seq_len, batch, 256)  \n",
    "#         conv_out = torch.reshape(conv_out, (conv_out.size(1), conv_out.size(0), conv_out.size(3)))\n",
    "#         encoder_in = self.encoder_pos_encoding(conv_out)\n",
    "#         encoder_in = conv_out\n",
    "\n",
    "#         print(\"pos encoding conv out succes\")\n",
    "#         print(encoder_in.shape)\n",
    "#         print(encoder_in.dtype)\n",
    "#         # encoder_out = encoder_out[:, 0, :]\n",
    "#         encoder_out = torch.reshape(encoder_out, (encoder_out.size(0), 1, encoder_out.size(1)))\n",
    "#         print(encoder_out.shape)\n",
    "        \n",
    "\n",
    "#         # transformer encoder layers\n",
    "#         encoder_out = self.trans_encoder1(conv_out)\n",
    "#         # encoder_out = self.trans_encoder1(encoder_in)\n",
    "#         encoder_out = self.trans_encoder2(encoder_out)\n",
    "#         encoder_out = self.trans_encoder3(encoder_out)\n",
    "#         encoder_out = self.trans_encoder4(encoder_out)\n",
    "\n",
    "#         print(\"encoder out succes\")\n",
    "\n",
    "#         # dense layer for intermediate output of decoder (CTC Loss)\n",
    "#         interm_encoder_out = self.encoder_out_dense(encoder_out)\n",
    "\n",
    "#         print(\"encoder dense out succes\")\n",
    "\n",
    "#         # add sinusodial positional information again\n",
    "#         encoder_out = self.encoder_pos_encoding(encoder_out)\n",
    "\n",
    "#         print(\"pos encoding encoder out succes\")\n",
    "#         # target sequence (shifted right (so with <BOS> token))\n",
    "#         # print(self.char_embedding)\n",
    "#         decoder_in = self.char_embedding(decoder_in_idxs)\n",
    "#         # sys.exit()\n",
    "        \n",
    "#         print(\"char embedding succes\")\n",
    "\n",
    "#         # add sinusoidal positional information to decoder input\n",
    "#         decoder_in = self.decoder_pos_encoding(decoder_in)\n",
    "        \n",
    "#         print(\"pos encoding decoder in succes\")\n",
    "\n",
    "#         # input encoder output and predicted chars into decoder\n",
    "#         decoder_out = self.trans_decoder1(decoder_in, encoder_out, self.target_mask)\n",
    "#         decoder_out = self.trans_decoder2(decoder_out, encoder_out, self.target_mask)\n",
    "#         decoder_out = self.trans_decoder3(decoder_out, encoder_out, self.target_mask)\n",
    "#         decoder_out = self.trans_decoder4(decoder_out, encoder_out, self.target_mask)\n",
    "\n",
    "#         print(\"decoder out succes\")\n",
    "\n",
    "#         # dense layer after decoder to predict one of all tokens (CE Loss)\n",
    "#         decoder_out = self.decoder_out_dense(decoder_out)\n",
    "\n",
    "#         print(\"decoder dense out succes\")\n",
    "#         return conv_out\n",
    "#         # return interm_encoder_out, decoder_out\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "hwr_transformer = HWRTransformer(INPUT_HEIGHT, input_width, len(char_to_idx_mapping), longest_label)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label text:\n",
      "-> said \"Nonsense.\" As usual, the optimists have been\n",
      "image tensor shape:\n",
      "-> torch.Size([1, 128, 2260])\n",
      "one hot label shape:\n",
      "-> torch.Size([56, 1, 82])\n",
      "label shifted right embedding index tensor shape:\n",
      "-> torch.Size([56, 1])\n",
      "torch.Size([1, 56, 1])\n",
      "\n",
      "Shape of output of encoder (CTC Loss):\n",
      "-> torch.Size([277, 1, 82])\n",
      "Shape of decoder output (CE Loss):\n",
      "-> torch.Size([56, 1, 82])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test image as tensor, test label as one hot encoded target characters, labels shifted right as indices for embedding table\n",
    "test_image, test_label_one_hot, labels_shifted_right_idxs = train_set[2]\n",
    "print(\"Label text:\\n->\", train_set.data['labels'][2])\n",
    "print(\"image tensor shape:\\n->\", test_image.shape)\n",
    "print(\"one hot label shape:\\n->\", test_label_one_hot.shape)\n",
    "# torch.set_printoptions(threshold=10000)\n",
    "# print(test_label_one_hot)\n",
    "print(\"label shifted right embedding index tensor shape:\\n->\", labels_shifted_right_idxs.shape)\n",
    "\n",
    "# create \"batch\" with single image\n",
    "test_image_batch = test_image.unsqueeze(0)\n",
    "labels_shifted_right_idxs_batch = labels_shifted_right_idxs.unsqueeze(0)\n",
    "\n",
    "plt.imshow(test_image_batch[0, 0, :, :], cmap = \"gray\")\n",
    "\n",
    "# test label = <BOS> *sentence in tokens* <EOS> <PAD> <PAD> ... \n",
    "out1, out2 = hwr_transformer(test_image_batch, labels_shifted_right_idxs_batch)\n",
    "# out1 = hwr_transformer(test_image_batch, label_shifted_right_idxs)\n",
    "print(\"\\nShape of output of encoder (CTC Loss):\\n->\", out1.shape)\n",
    "print(\"Shape of decoder output (CE Loss):\\n->\", out2.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define hybrid loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridLoss(nn.Module):\n",
    "    def __init__(self, balance):\n",
    "        super(HybridLoss, self).__init__()\n",
    "        # allignment probabilities over encoded input sequence and target sequence \n",
    "        self.interm_CTCloss = nn.CTCLoss()\n",
    "        # difference between decodeced input sequence and target sequence\n",
    "        self.output_CELoss = nn.CrossEntropyLoss()\n",
    "\n",
    "        # balance between CTC Loss and CE Loss (R: [0, 1])\n",
    "        if balance < 0 or balance > 1:\n",
    "            raise ValueError(\"Balance should be a value between 0 (only output CELoss) and 1 (only intermediate CTCLoss)\")\n",
    "        self.balance = balance\n",
    "\n",
    "    def setBalance(self, balance):\n",
    "        self.balance = balance\n",
    "\n",
    "    def forward(self, encoder_output, encoder_target, decoder_output, decoder_target):\n",
    "        interm_loss = self.interm_CTCloss(encoder_output, encoder_target)\n",
    "        output_loss = self.output_CELoss(decoder_output, decoder_target)\n",
    "        \n",
    "        return (self.balance * interm_loss + (1 - self.balance) * output_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in the paper they only used balance to test efficiousness of the hybrid loss, \n",
    "#   and train with a balance of 0.5\n",
    "hybrid_loss_func = HybridLoss(0.5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(hwr_transformer.parameters(), lr = 0.0001)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, test_loader, loss_func, optim, epochs):\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        running_loss_train = 0 \n",
    "        running_loss_test = 0\n",
    "        \n",
    "        # train\n",
    "        for i, data in enumerate(train_loader):\n",
    "            # batched inputs (encoder = images, decoder = labels_shifted_rigth) and labels\n",
    "            images, one_hot_labels, labels_shifted_right_idxs = data\n",
    "            \n",
    "            # zero gradients before any calculations\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # predict\n",
    "            interm_outputs, decoder_outputs = model(images, labels_shifted_right_idxs)\n",
    "            print(\"epoch:\", epoch, \" - i:\", i, \" | \", interm_outputs.shape, decoder_outputs.shape)\n",
    "            \n",
    "            # TODO: calc loss \n",
    "            # loss = loss_func()\n",
    "            \n",
    "            # take step along loss gradients\n",
    "            # optimizer.step()\n",
    "            \n",
    "            # add to running loss\n",
    "            # running_loss_train += loss.item()\n",
    "        \n",
    "        # test\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(test_loader):\n",
    "                # batched inputs (encoder = images, decoder = labels_shifted_rigth) and labels\n",
    "                images, one_hot_labels, labels_shifted_right_idxs = data\n",
    "                \n",
    "                # predict\n",
    "                interm_outputs, decoder_outputs = model(images, labels_shifted_right_idxs)\n",
    "                \n",
    "                # TODO: calc loss \n",
    "                # loss = loss_func()\n",
    "                \n",
    "                # add to running loss\n",
    "                # running_loss_test += loss.item()\n",
    "            \n",
    "        # add to loss value lists\n",
    "        # train_losses.append(running_loss_train / len(train_loader))\n",
    "        # test_losses.append(running_loss_test / len(test_loader))\n",
    "        \n",
    "    # return train_losses, test_losses"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 56, 1])\n",
      "epoch: 0  - i: 0  |  torch.Size([277, 16, 82]) torch.Size([56, 16, 82])\n",
      "torch.Size([16, 56, 1])\n",
      "epoch: 0  - i: 1  |  torch.Size([277, 16, 82]) torch.Size([56, 16, 82])\n",
      "torch.Size([16, 56, 1])\n",
      "epoch: 0  - i: 2  |  torch.Size([277, 16, 82]) torch.Size([56, 16, 82])\n",
      "torch.Size([16, 56, 1])\n",
      "epoch: 0  - i: 3  |  torch.Size([277, 16, 82]) torch.Size([56, 16, 82])\n",
      "torch.Size([16, 56, 1])\n",
      "epoch: 0  - i: 4  |  torch.Size([277, 16, 82]) torch.Size([56, 16, 82])\n",
      "torch.Size([16, 56, 1])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train(hwr_transformer, train_loader, test_loader, hybrid_loss_func, optimizer, EPOCHS)\n",
      "Cell \u001b[0;32mIn[53], line 18\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, test_loader, loss_func, optim, epochs)\u001b[0m\n\u001b[1;32m     15\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     17\u001b[0m     \u001b[39m# predict\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m     interm_outputs, decoder_outputs \u001b[39m=\u001b[39m model(images, labels_shifted_right_idxs)\n\u001b[1;32m     19\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mepoch:\u001b[39m\u001b[39m\"\u001b[39m, epoch, \u001b[39m\"\u001b[39m\u001b[39m - i:\u001b[39m\u001b[39m\"\u001b[39m, i, \u001b[39m\"\u001b[39m\u001b[39m | \u001b[39m\u001b[39m\"\u001b[39m, interm_outputs\u001b[39m.\u001b[39mshape, decoder_outputs\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     21\u001b[0m     \u001b[39m# TODO: calc loss \u001b[39;00m\n\u001b[1;32m     22\u001b[0m     \u001b[39m# loss = loss_func()\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m \n\u001b[1;32m     30\u001b[0m \u001b[39m# test\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[46], line 38\u001b[0m, in \u001b[0;36mHWRTransformer.forward\u001b[0;34m(self, input_image, decoder_in_embed_idxs)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, input_image, decoder_in_embed_idxs):\n\u001b[1;32m     36\u001b[0m     \u001b[39m# forward through backbone convolutional neural network\u001b[39;00m\n\u001b[1;32m     37\u001b[0m     \u001b[39mprint\u001b[39m(decoder_in_embed_idxs\u001b[39m.\u001b[39mshape)\n\u001b[0;32m---> 38\u001b[0m     cnn_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcnn(input_image)\n\u001b[1;32m     40\u001b[0m     \u001b[39m# add pre-encoder positional information\u001b[39;00m\n\u001b[1;32m     41\u001b[0m     cnn_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder_pos_encoding(cnn_out)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[43], line 77\u001b[0m, in \u001b[0;36mCNN.forward\u001b[0;34m(self, input_img)\u001b[0m\n\u001b[1;32m     74\u001b[0m conv_out \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mreshape(conv_out, (conv_out\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m), conv_out\u001b[39m.\u001b[39msize(\u001b[39m3\u001b[39m), conv_out\u001b[39m.\u001b[39msize(\u001b[39m2\u001b[39m), conv_out\u001b[39m.\u001b[39msize(\u001b[39m1\u001b[39m)))\n\u001b[1;32m     76\u001b[0m \u001b[39m# upscale from 128 to 256\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m conv_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdense(conv_out)\n\u001b[1;32m     79\u001b[0m \u001b[39m# reshape to (seq, batch, embed_dim)\u001b[39;00m\n\u001b[1;32m     80\u001b[0m conv_out \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mreshape(conv_out, (conv_out\u001b[39m.\u001b[39msize(\u001b[39m1\u001b[39m), conv_out\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m), conv_out\u001b[39m.\u001b[39msize(\u001b[39m3\u001b[39m)))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(hwr_transformer, train_loader, test_loader, hybrid_loss_func, optimizer, EPOCHS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
