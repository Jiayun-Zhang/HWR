{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lightweight Transformer-based Model for Handwritten Character Recognition \n",
    "(https://hal.science/hal-03685976/file/A_Light_Transformer_Based_Architecture_for_Handwritten_Text_Recognition.pdf)\n",
    "\n",
    "## ***note: Has a CNN backbone***\n",
    "\n",
    "-----------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture  \n",
    "Build up with a double Transformer architecture:  \n",
    "- Image transformer as encoder: Extracts the visual features\n",
    "- Text transformer as decoder: Language modeling, generates word-sections\n",
    "             sequence using visual features and previous predictions\n",
    "\n",
    "### Encoder:  \n",
    "- CNN Backbone (5 convolutions)\n",
    "- Sinusodial position encoding  \n",
    "- 4 layer transformer layer encoder\n",
    "\n",
    "### Decoder: \n",
    "- Takes encoder output and along with sequence of previously predicted characters\n",
    "- Additional loss in the middle of the network to help convergence\n",
    "\n",
    "### Hybrid loss:\n",
    "- CTC and CE Loss combined, CTC on intermediate encoder output, CE on decoder output\n",
    "\n",
    "--------------\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "from collections import OrderedDict, Counter\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision as tv\n",
    "from torchvision.io import read_image\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/usr/bin/python3'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.executable"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = f\"/home/hkolstee/uniprojects/DATA/HWR/IAM-data/IAM-data/\"\n",
    "TRAIN_TEST_SPLIT = 0.2\n",
    "BATCH_SIZE = 16\n",
    "INPUT_HEIGHT = 128\n",
    "# input width -> largest width in batch\n",
    "#   images max resized and subsequently padded to get to width\n",
    "EPOCHS = 500"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_names</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a03-017-07.png</td>\n",
       "      <td>into the pro-communist north and the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a03-017-05.png</td>\n",
       "      <td>to 1958 kept the kingdom in peace, though</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a03-017-08.png</td>\n",
       "      <td>pro-western centre and south.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a03-017-02.png</td>\n",
       "      <td>in Phnom Penh indicate that he still regards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a03-017-06.png</td>\n",
       "      <td>at the cost of virtual partition of the country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7453</th>\n",
       "      <td>d06-000-08.png</td>\n",
       "      <td>fears are based upon completely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7454</th>\n",
       "      <td>d06-000-05.png</td>\n",
       "      <td>is worrying them, to find the original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7455</th>\n",
       "      <td>d06-000-09.png</td>\n",
       "      <td>irrational pre-conceived notions - or to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7456</th>\n",
       "      <td>d06-000-02.png</td>\n",
       "      <td>already suggested, not to be silly or</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7457</th>\n",
       "      <td>d06-000-00.png</td>\n",
       "      <td>In the first place it is not a great deal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7458 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           img_names                                           labels\n",
       "0     a03-017-07.png             into the pro-communist north and the\n",
       "1     a03-017-05.png        to 1958 kept the kingdom in peace, though\n",
       "2     a03-017-08.png                    pro-western centre and south.\n",
       "3     a03-017-02.png     in Phnom Penh indicate that he still regards\n",
       "4     a03-017-06.png  at the cost of virtual partition of the country\n",
       "...              ...                                              ...\n",
       "7453  d06-000-08.png                  fears are based upon completely\n",
       "7454  d06-000-05.png           is worrying them, to find the original\n",
       "7455  d06-000-09.png         irrational pre-conceived notions - or to\n",
       "7456  d06-000-02.png            already suggested, not to be silly or\n",
       "7457  d06-000-00.png        In the first place it is not a great deal\n",
       "\n",
       "[7458 rows x 2 columns]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.read_fwf(DATA_PATH + \"iam_lines_gt.txt\", header = None)\n",
    "raw_data = raw_data.values.tolist()\n",
    "\n",
    "data = {'img_names': np.squeeze(raw_data[::2]),\n",
    "        'labels': np.squeeze(raw_data[1::2])}\n",
    "\n",
    "data = pd.DataFrame(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "an Italian who is perhaps the best Valet de Chambre\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb89f07f0a0>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# example (label indx unknown)\n",
    "ex_label = \"an Italian who is perhaps the best Valet de Chambre\" \n",
    "print(ex_label)\n",
    "# print(data['labels'][0])\n",
    "image = read_image(os.path.join(DATA_PATH, \"img\", \"g06-026i-01.png\"))\n",
    "plt.imshow(image[0, :, :], cmap = \"gray\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first, we need the input/image width we have to resize the images to.  \n",
    "This is the largest image width in the entire batch of images (source paper randomly added/removed new augments each training epoch).   \n",
    "For now we just take the largest width in the original images.  \n",
    "  \n",
    "The labels are later padded to the largest label size in the dataset, such that we also need to know the longest label size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBiggestWidth(data: pd.DataFrame):\n",
    "    biggest_width = 0\n",
    "\n",
    "    for index in range(len(data['img_names'])):\n",
    "        image_path = os.path.join(DATA_PATH, \"img\", data['img_names'][index])\n",
    "        image = read_image(image_path)\n",
    "        \n",
    "        if (image.size(2) > biggest_width):\n",
    "            biggest_width = image.size(2)\n",
    "\n",
    "    return biggest_width\n",
    "\n",
    "def getLongestLabel(data: pd.DataFrame):\n",
    "    longest = 0\n",
    "    \n",
    "    for index in range(len(data['labels'])):\n",
    "        if (len(data['labels'][index]) > longest):\n",
    "            longest = len(data['labels'][index])\n",
    "            \n",
    "    return longest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Biggest width needed to pad all images to this width for the input into the encoder.  \n",
    "Longest label needed to pad all labels to this length for the input into the decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2260\n",
      "56\n"
     ]
    }
   ],
   "source": [
    "input_width = getBiggestWidth(data)\n",
    "print(input_width)\n",
    "\n",
    "longest_label = getLongestLabel(data)\n",
    "# <BOS> and <EOS> tokens not counted\n",
    "longest_label += 2\n",
    "print(longest_label)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Data augmentation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resize and pad images to largest width in dataset  \n",
    "### ***NOTE: Not sure if padding should be all at the right part of the image or both sides***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resizes to largest width in batch x 128, keeping aspect ratio and padding image\n",
    "class resizeImage(object):\n",
    "    def __init__(self, resize_width, resize_height):\n",
    "        self.resize_width = resize_width\n",
    "        self.resize_height = resize_height\n",
    "    \n",
    "    def __call__(self, image):\n",
    "        # check if resizing to correct height while keeping aspect ratio does not overshoot correct width\n",
    "        aspect_ratio_width = int((self.resize_height / image.size(1)) * image.size(2))\n",
    "        if (aspect_ratio_width > self.resize_width):\n",
    "            # calculate max ratio of change for not overshooting resize width while keeping aspect ratio \n",
    "            max_ratio = self.resize_width / image.size(2)\n",
    "            max_resize_height = int(max_ratio * image.size(1))\n",
    "            # calc up and down padding\n",
    "            padding_up = int(((self.resize_height - max_resize_height) / 2))\n",
    "            padding_down = self.resize_height - max_resize_height - padding_up\n",
    "            # change resize height to max calculated resize height\n",
    "            new_resize_height = max_resize_height\n",
    "        else:\n",
    "            padding_up = 0\n",
    "            padding_down = 0\n",
    "            new_resize_height = self.resize_height\n",
    "\n",
    "        # resize to correct image height, while keeping aspect ratio\n",
    "        resize_transform = tv.transforms.Resize((new_resize_height, self.resize_width), antialias = True)\n",
    "        resized = resize_transform(image)\n",
    "        \n",
    "        # pad to correct width (and height if necessary)\n",
    "        padding_left = int(((self.resize_width - resized.size(2)) / 2))\n",
    "        padding_right = self.resize_width - resized.size(2) - padding_left\n",
    "        resized_padded = F.pad(resized, (padding_left, padding_right, padding_up, padding_down), mode = \"constant\", value = 255)\n",
    "\n",
    "        return resized_padded"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This example because it previously overshot the correct width using the height measurements for the aspect ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "an Italian who is perhaps the best Valet de Chambre\n",
      "torch.Size([1, 86, 1758])\n",
      "torch.Size([1, 128, 2260])\n",
      "torch.uint8\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(ex_label)\n",
    "image = read_image(os.path.join(DATA_PATH, \"img\", \"g06-026i-01.png\"))\n",
    "print(image.shape)\n",
    "\n",
    "resize_transform = resizeImage(input_width, INPUT_HEIGHT)\n",
    "resized_image = resize_transform(image)\n",
    "plt.imshow(resized_image[0, :, :], cmap = \"gray\")\n",
    "print(resized_image.shape)\n",
    "print(resized_image.dtype)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resize and pad for the whole dataset and save in a new dir such that we don't have to do this each epoch. TODO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size = TRAIN_TEST_SPLIT)\n",
    "\n",
    "# reset indices from current random state\n",
    "train.reset_index(inplace = True)\n",
    "test.reset_index(inplace = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create custom pytorch dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For character level embedding (decoder input) we find out how many characters are present in the dataset. By counting the characters we give the most common characters the lowest indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a dict of uniques chars sorted on how common they are in the dataset labels\n",
    "def uniqueCharsByMostCommon(data: pd.DataFrame):\n",
    "    sortedDict = OrderedDict(Counter(''.join(data['labels'].values)).most_common())\n",
    "    newDict = {}\n",
    "    \n",
    "    # first add pad, begin of sentence, and end of sentence tokens\n",
    "    newDict[\"<PAD>\"] = 0\n",
    "    newDict[\"<BOS>\"] = 1\n",
    "    newDict[\"<EOS>\"] = 2\n",
    "    \n",
    "    for idx, char in enumerate(sortedDict):\n",
    "        newDict[char] = idx + 3\n",
    "    \n",
    "    return newDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<PAD>': 0,\n",
       " '<BOS>': 1,\n",
       " '<EOS>': 2,\n",
       " ' ': 3,\n",
       " 'e': 4,\n",
       " 't': 5,\n",
       " 'a': 6,\n",
       " 'o': 7,\n",
       " 'n': 8,\n",
       " 'i': 9,\n",
       " 's': 10,\n",
       " 'r': 11,\n",
       " 'h': 12,\n",
       " 'l': 13,\n",
       " 'd': 14,\n",
       " 'c': 15,\n",
       " 'u': 16,\n",
       " 'm': 17,\n",
       " 'f': 18,\n",
       " 'p': 19,\n",
       " 'w': 20,\n",
       " 'g': 21,\n",
       " 'y': 22,\n",
       " 'b': 23,\n",
       " '.': 24,\n",
       " ',': 25,\n",
       " 'v': 26,\n",
       " 'k': 27,\n",
       " \"'\": 28,\n",
       " '\"': 29,\n",
       " '-': 30,\n",
       " 'T': 31,\n",
       " 'I': 32,\n",
       " 'M': 33,\n",
       " 'A': 34,\n",
       " 'S': 35,\n",
       " 'B': 36,\n",
       " 'P': 37,\n",
       " 'H': 38,\n",
       " 'W': 39,\n",
       " 'C': 40,\n",
       " 'N': 41,\n",
       " 'G': 42,\n",
       " 'x': 43,\n",
       " 'R': 44,\n",
       " 'L': 45,\n",
       " 'E': 46,\n",
       " 'D': 47,\n",
       " 'F': 48,\n",
       " '0': 49,\n",
       " '1': 50,\n",
       " 'j': 51,\n",
       " 'O': 52,\n",
       " 'q': 53,\n",
       " '!': 54,\n",
       " 'U': 55,\n",
       " '(': 56,\n",
       " 'K': 57,\n",
       " '?': 58,\n",
       " 'z': 59,\n",
       " '3': 60,\n",
       " ')': 61,\n",
       " '9': 62,\n",
       " ';': 63,\n",
       " 'V': 64,\n",
       " '2': 65,\n",
       " 'J': 66,\n",
       " 'Y': 67,\n",
       " ':': 68,\n",
       " '5': 69,\n",
       " '8': 70,\n",
       " '4': 71,\n",
       " '6': 72,\n",
       " '#': 73,\n",
       " '&': 74,\n",
       " '7': 75,\n",
       " '/': 76,\n",
       " 'Q': 77,\n",
       " 'X': 78,\n",
       " '*': 79,\n",
       " 'Z': 80,\n",
       " '+': 81}"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get mapping before splitting dataset\n",
    "char_to_idx_mapping = uniqueCharsByMostCommon(data)\n",
    "char_to_idx_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HandWritingDataset(Dataset):\n",
    "    def __init__(self, data: pd.DataFrame, data_path, img_width, img_height, char_to_idx_mapping: dict, max_label_size):\n",
    "        self.data = data\n",
    "        self.data_path = data_path\n",
    "        self.img_width = img_width\n",
    "        self.img_height = img_height\n",
    "        self.label_size = max_label_size\n",
    "\n",
    "        self.char_to_idx_mapping = char_to_idx_mapping\n",
    "        self.idx_to_char_mapping = {value: key for key, value in self.char_to_idx_mapping.items()}\n",
    "\n",
    "        self.createLabelEncodings()\n",
    "        # self.reshapeAndStoreImages()\n",
    "\n",
    "        # calc mean and std of images combines for standardization\n",
    "        mean, std = self.calcImagesMeanStd()\n",
    "\n",
    "        # composed transform\n",
    "        self.transforms = tv.transforms.Compose([resizeImage(img_width, img_height),\n",
    "                                                tv.transforms.Normalize(mean, std)])\n",
    "\n",
    "\n",
    "    def createLabelEncodings(self):\n",
    "        # change character level strings to embed indices \n",
    "        #   (embedding itself calculated in forward pass)\n",
    "        self.labels_as_idxs = [torch.tensor([[self.char_to_idx_mapping[char]] for char in label]) for label in data['labels']] \n",
    "        # add <EOS> tokens at the end of sentences\n",
    "        self.labels_as_idxs = [torch.cat([label, torch.tensor([[self.char_to_idx_mapping['<EOS>']]])]) for label in self.labels_as_idxs]\n",
    "        # input into decoder shifted right (while training) and <BOS> token inserted at start\n",
    "        self.decoder_input_as_idxs = [torch.cat([torch.tensor([[self.char_to_idx_mapping['<BOS>']]]), label]) for label in self.labels_as_idxs]\n",
    "        \n",
    "        # target lengths for CTC loss\n",
    "        self.labels_lengths = [len(label) for label in self.labels_as_idxs]\n",
    "\n",
    "        # pad labels embedding indices to largest label length with <PAD> token\n",
    "        self.labels_as_idxs = [F.pad(label, (0, 0, 0, self.label_size - label.shape[0]), mode = 'constant', value = self.char_to_idx_mapping['<PAD>']) \\\n",
    "                               for label in self.labels_as_idxs]\n",
    "        \n",
    "        # pad decoder input char embedding indices to largest label length with <PAD> tokens \n",
    "        self.decoder_input_as_idxs = [F.pad(label, (0, 0, 0, self.label_size - label.shape[0]), mode = 'constant', value = self.char_to_idx_mapping['<PAD>']) \\\n",
    "                               for label in self.decoder_input_as_idxs]\n",
    "        \n",
    "        # transform target labels into one hot encoding vectors\n",
    "        self.labels_as_onehot =  [F.one_hot(label, num_classes = len(self.char_to_idx_mapping)) for label in self.labels_as_idxs]        \n",
    "\n",
    "    # reshapes + pads the images to the correct input width and height\n",
    "    # def reshapeAndStoreImages(self):\n",
    "    #     self.images = []\n",
    "\n",
    "    #     for image_name in self.data['img_names']:\n",
    "    #         # read image\n",
    "    #         image = read_image(os.path.join(self.data_path, \"img\", image_name))\n",
    "    #         # resize + pad image to correct input size\n",
    "    #         resized_padded = resizeImage(image, self.img_width, self.img_height)\n",
    "    #         # store in list of tensors\n",
    "    #         self.images.append(resized_padded)\n",
    "\n",
    "            \n",
    "    # Function to calc the mean and std of a dataset to use in image standardization \n",
    "    def calcImagesMeanStd(self):\n",
    "        running_mean = 0\n",
    "        running_std = 0\n",
    "\n",
    "        for image_name in self.data['img_names']:\n",
    "            image = read_image(os.path.join(self.data_path, \"img\", image_name))\n",
    "\n",
    "            mean = torch.mean(image.float())\n",
    "            std = torch.std(image.float())\n",
    "\n",
    "            running_mean += mean\n",
    "            running_std += std\n",
    "\n",
    "        return (running_mean / len(self.data)), (running_std / len(self.data))\n",
    "    \n",
    "    # transforms done in __getitem__ so that images can be stored as Byte tensors (-> less memory and kernel does not crash)\n",
    "    def __getitem__(self, index):\n",
    "        # image = self.images[index].float()\n",
    "        image = read_image(os.path.join(self.data_path, \"img\", self.data['img_names'][index])).float()\n",
    "        # transform image (resize/pas + normalize)\n",
    "        image = self.transforms(image)\n",
    "        # paper adds gaussian noise to image (sqrt(0.1) * rand from gaussian distri)\n",
    "        #   TODO: add to transforms for cleaner code\n",
    "        image += ((0.1**0.5) * torch.randn(image.shape)) * 0.75\n",
    "\n",
    "        # label\n",
    "        encoder_label = self.labels_as_idxs[index].squeeze()\n",
    "        decoder_label = self.labels_as_onehot[index]\n",
    "            # used for CTC Loss\n",
    "        label_length = self.labels_lengths[index]\n",
    "        # label shifted right\n",
    "        decoder_in = self.decoder_input_as_idxs[index]\n",
    "\n",
    "        # image = tensor, label = one hot encoded target characters, decoder_in = label shifted right as indices for embedding table\n",
    "        return image, encoder_label, label_length, decoder_label, decoder_in\n",
    "\n",
    "    def __len__(self):\n",
    "        # return length of column\n",
    "        return len(self.data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create datasets and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets\n",
    "train_set = HandWritingDataset(train, DATA_PATH, input_width, INPUT_HEIGHT, char_to_idx_mapping, longest_label)\n",
    "test_set = HandWritingDataset(test, DATA_PATH, input_width, INPUT_HEIGHT, char_to_idx_mapping, longest_label)\n",
    "\n",
    "# dataloaders\n",
    "train_loader = DataLoader(train_set, batch_size = BATCH_SIZE, shuffle = True)\n",
    "test_loader = DataLoader(test_set, batch_size = BATCH_SIZE, shuffle = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sinusodial positional encoding  \n",
    "(can be changed to nn.embedding layers if we don't get good results, however that is not exactly sinusodial pos encoding like in the paper I think)\n",
    "\n",
    "<!-- **CHANGED TO NN.EMBEDDING IN MODEL**   -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinPosEncoding(nn.Module):\n",
    "    def __init__(self, dimensionality):\n",
    "        super(SinPosEncoding, self).__init__()\n",
    "        self.dims = dimensionality\n",
    "        self.max_len = 1000\n",
    "\n",
    "        # position vector\n",
    "        positions = torch.arange(0, self.max_len).unsqueeze(1)\n",
    "        # calculate added angle for sin/cos\n",
    "        angle = torch.exp(torch.arange(0, self.dims, 1) * (-np.log(10000.0) / self.dims))\n",
    "\n",
    "        # initialize the 2D positional encodings array\n",
    "        pos_encodings = torch.zeros(self.max_len, 1, self.dims)\n",
    "        # calucalte encodings\n",
    "        pos_encodings[:, 0, :] = torch.sin(positions * angle)\n",
    "\n",
    "        # add to buffer for training performance (?)\n",
    "        self.register_buffer('pos_encodings', pos_encodings)\n",
    "\n",
    "    \n",
    "    def forward(self, input: torch.Tensor):\n",
    "        # print(\"\\n\", input.shape)\n",
    "        # print(self.pos_encodings.shape)\n",
    "        # print(self.pos_encodings[0:input.size(0)].shape)\n",
    "        # adds the positional encoding elementwise to the tensor (seqlength, batch, embeddims)\n",
    "        input += self.pos_encodings[0:input.size(0)]\n",
    "        # print(\"succes\\n\")\n",
    "\n",
    "        return input"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_height, input_width):\n",
    "        super(CNN, self).__init__()\n",
    "        # convolutional block (5 convolutions)\n",
    "        # first convolution\n",
    "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 8, kernel_size = (3,3))\n",
    "        width = input_width - 2\n",
    "        height = input_height - 2\n",
    "        self.leakyRelu = nn.LeakyReLU()     # reuse in later layers\n",
    "        self.maxPool = nn.MaxPool2d((2,2))  # reuse in later layers\n",
    "        width = int(np.floor(width/2))\n",
    "        height = int(np.floor(height/2))\n",
    "        self.layerNorm1 = nn.LayerNorm(normalized_shape = [8, height, width])\n",
    "        self.dropout = nn.Dropout(0.2)      # reuse in later layers\n",
    "\n",
    "        # second convolutional layer\n",
    "        self.conv2 = nn.Conv2d(in_channels = 8, out_channels = 16, kernel_size = (3, 3))\n",
    "        width -= 2\n",
    "        height -= 2\n",
    "        # after maxpool\n",
    "        width = int(np.floor(width/2))\n",
    "        height = int(np.floor(height/2))\n",
    "        self.layerNorm2 = nn.LayerNorm(normalized_shape = [16, height, width])\n",
    "\n",
    "        # third convolutional layer\n",
    "        self.conv3 = nn.Conv2d(in_channels = 16, out_channels = 32, kernel_size = (3, 3))\n",
    "        width -= 2\n",
    "        height -= 2\n",
    "        # after maxpool\n",
    "        width = int(np.floor(width/2))\n",
    "        height = int(np.floor(height/2))\n",
    "        self.layerNorm3 = nn.LayerNorm(normalized_shape = [32, height, width])\n",
    "\n",
    "        # forth convolutional layer\n",
    "        self.conv4 = nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = (3, 3))\n",
    "        width -= 2\n",
    "        height -= 2\n",
    "        # no maxpool\n",
    "        self.layerNorm4 = nn.LayerNorm(normalized_shape = [64, height, width])\n",
    "\n",
    "        # fifth convolutional layer (kernel size to better match shape of character)\n",
    "        self.conv5 = nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size = (4, 2))\n",
    "        width -= 1\n",
    "        height -= 3\n",
    "        # no maxpool\n",
    "        self.layerNorm5 = nn.LayerNorm(normalized_shape = [128, height, width])\n",
    "\n",
    "        # following is convolution with width 1 which is used to flatten the current output\n",
    "        self.flattenConv = nn.Conv2d(in_channels = 128, out_channels = 128, kernel_size = (height, 1))\n",
    "        self.layerNorm6 = nn.LayerNorm(normalized_shape = [128, 1, width])\n",
    "\n",
    "        # dense layer to upscale from 128 to 256\n",
    "        self.dense = nn.Linear(in_features = 128, out_features = 256)\n",
    "\n",
    "    def forward(self, input_img):\n",
    "        # first conv\n",
    "        conv_out = self.layerNorm1(self.maxPool(self.leakyRelu(self.conv1(input_img))))\n",
    "        conv_out = self.dropout(conv_out)\n",
    "        # second conv\n",
    "        conv_out = self.layerNorm2(self.maxPool(self.leakyRelu(self.conv2(conv_out))))\n",
    "        conv_out = self.dropout(conv_out)\n",
    "        # third conv\n",
    "        conv_out = self.layerNorm3(self.maxPool(self.leakyRelu(self.conv3(conv_out))))\n",
    "        conv_out = self.dropout(conv_out)\n",
    "        # forth conv\n",
    "        conv_out = self.layerNorm4(self.leakyRelu(self.conv4(conv_out)))\n",
    "        # fifth conv\n",
    "        conv_out = self.layerNorm5(self.leakyRelu(self.conv5(conv_out)))\n",
    "\n",
    "        # flatten layer\n",
    "        conv_out = self.layerNorm6(self.leakyRelu(self.flattenConv(conv_out)))\n",
    "\n",
    "        # reshape from ((batch, 128, 1, x) -> (batch, x, 1, 128)) for dense layer\n",
    "        conv_out = torch.reshape(conv_out, (conv_out.size(0), conv_out.size(3), conv_out.size(2), conv_out.size(1)))\n",
    "\n",
    "        # upscale from 128 to 256\n",
    "        conv_out = self.dense(conv_out)\n",
    "\n",
    "        # reshape to (seq, batch, embed_dim)\n",
    "        conv_out = torch.reshape(conv_out, (conv_out.size(1), conv_out.size(0), conv_out.size(3)))\n",
    "        \n",
    "        return conv_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HWRTransformerEncoder(nn.Module):\n",
    "    def __init__(self, total_nr_of_tokens):\n",
    "        super(HWRTransformerEncoder, self).__init__()\n",
    "        # transformer encoder layers (4 stacked transformer encoder layers (4 headed attention))\n",
    "        self.trans_encoder1 = nn.TransformerEncoderLayer(d_model = 256, nhead = 4, dim_feedforward = 1024, dropout = 0.2)\n",
    "        self.trans_encoder2 = nn.TransformerEncoderLayer(d_model = 256, nhead = 4, dim_feedforward = 1024, dropout = 0.2)\n",
    "        self.trans_encoder3 = nn.TransformerEncoderLayer(d_model = 256, nhead = 4, dim_feedforward = 1024, dropout = 0.2)\n",
    "        self.trans_encoder4 = nn.TransformerEncoderLayer(d_model = 256, nhead = 4, dim_feedforward = 1024, dropout = 0.2)\n",
    "\n",
    "        # dense layer for backprop CTC Loss of intermediate encoder result\n",
    "        self.encoder_out_dense = nn.Linear(256, total_nr_of_tokens)\n",
    "\n",
    "    def forward(self, encoder_input):\n",
    "        # transformer encoder layers\n",
    "        encoder_out = self.trans_encoder1(encoder_input)\n",
    "        encoder_out = self.trans_encoder2(encoder_out)\n",
    "        encoder_out = self.trans_encoder3(encoder_out)\n",
    "        encoder_out = self.trans_encoder4(encoder_out)\n",
    "\n",
    "        return encoder_out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HWRTransformerDecoder(nn.Module):\n",
    "    def __init__(self, total_nr_of_tokens):\n",
    "        super(HWRTransformerDecoder, self).__init__()\n",
    "\n",
    "        # transformer decoder layers (4 stacked transformer encoder layers (4 headed attention))\n",
    "        self.trans_decoder1 = nn.TransformerDecoderLayer(d_model = 256, nhead = 4, dim_feedforward = 1024, dropout = 0.2)\n",
    "        self.trans_decoder2 = nn.TransformerDecoderLayer(d_model = 256, nhead = 4, dim_feedforward = 1024, dropout = 0.2)\n",
    "        self.trans_decoder3 = nn.TransformerDecoderLayer(d_model = 256, nhead = 4, dim_feedforward = 1024, dropout = 0.2)\n",
    "        self.trans_decoder4 = nn.TransformerDecoderLayer(d_model = 256, nhead = 4, dim_feedforward = 1024, dropout = 0.2)\n",
    "\n",
    "        self.decoder_out_dense = nn.Linear(256, total_nr_of_tokens)\n",
    "\n",
    "    def forward(self, decoder_in, encoder_out, target_mask):\n",
    "        # input encoder output and predicted chars into decoder\n",
    "        decoder_out = self.trans_decoder1(decoder_in, encoder_out, target_mask)\n",
    "        decoder_out = self.trans_decoder2(decoder_out, encoder_out, target_mask)\n",
    "        decoder_out = self.trans_decoder3(decoder_out, encoder_out, target_mask)\n",
    "        decoder_out = self.trans_decoder4(decoder_out, encoder_out, target_mask)\n",
    "\n",
    "        # dense layer after decoder to predict one of all tokens (CE Loss)\n",
    "        decoder_out = self.decoder_out_dense(decoder_out)\n",
    "\n",
    "        return decoder_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HWRTransformer(nn.Module):\n",
    "    def __init__(self, input_height, input_width, total_nr_of_tokens, longest_label_size):\n",
    "        super(HWRTransformer, self).__init__()\n",
    "        # CNN backbone to extract optical features of input image\n",
    "        self.cnn = CNN(input_height, input_width)\n",
    "\n",
    "        # pre-encoder positional information\n",
    "        self.encoder_pos_encoding = SinPosEncoding(dimensionality = 256)\n",
    "\n",
    "        # Transformer encoder\n",
    "        self.transformer_encoder = HWRTransformerEncoder(total_nr_of_tokens)\n",
    "        # dense layer for intermediate output (to backprop with CTC Loss)\n",
    "        self.encoder_out_dense = nn.Linear(256, total_nr_of_tokens)\n",
    "\n",
    "        # character embedding (dim rule of thumb -> 4th sqrt of nr_embeddings: for ~80 = 3) \n",
    "        #      NOTE: wrong, appearantly dims (encoder output, target embedding) need to be the same\n",
    "        # <PAD> embedding idx = 0\n",
    "        self.char_embedding = nn.Embedding(total_nr_of_tokens, 256, padding_idx = 0)\n",
    "\n",
    "        # Transformer decoder \n",
    "        self.decoder_target_mask = self.make_target_mask(longest_label_size)\n",
    "        self.transformer_decoder = HWRTransformerDecoder(total_nr_of_tokens)\n",
    "\n",
    "    # create a target mask for decoder input\n",
    "    #   masks the future target characters from being seen by the model before they should\n",
    "    def make_target_mask(self, size):\n",
    "        mask = torch.zeros((size, size), dtype = torch.float32)\n",
    "        \n",
    "        for i in range(size):\n",
    "            for j in range(size):\n",
    "                if (j > i):\n",
    "                    mask[i][j] = float('-inf')\n",
    "        return mask\n",
    "    \n",
    "    def forward(self, input_image, decoder_in_embed_idxs):\n",
    "        # forward through backbone convolutional neural network\n",
    "        cnn_out = self.cnn(input_image)\n",
    "\n",
    "        # add pre-encoder positional information\n",
    "        cnn_out = self.encoder_pos_encoding(cnn_out)\n",
    "        \n",
    "        # forward through transformer encoder\n",
    "        encoder_out = self.transformer_encoder(cnn_out)\n",
    "        # dense layer for intermediate output (to backprop with CTC Loss)\n",
    "        interm_encoder_out = self.encoder_out_dense(encoder_out)\n",
    "\n",
    "        # add pre-decoder positional information\n",
    "        encoder_out = self.encoder_pos_encoding(encoder_out)\n",
    "\n",
    "        # embed character indices for input into decoder\n",
    "        shifted_target = self.char_embedding(decoder_in_embed_idxs)\n",
    "        # reshape from (batch, seq_len, 1, embed_dim) -> (seq_len, batch, embed_dim)\n",
    "        shifted_target = torch.reshape(shifted_target, (shifted_target.size(1), shifted_target.size(0), shifted_target.size(3)))\n",
    "\n",
    "        # forward through transformer decoder\n",
    "        decoder_out = self.transformer_decoder(shifted_target, encoder_out, self.decoder_target_mask)\n",
    "\n",
    "        return interm_encoder_out, decoder_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class HWRTransformer(nn.Module):\n",
    "#     def __init__(self, input_width, input_height, total_nr_of_tokens, longest_label):\n",
    "#         super(HWRTransformer, self).__init__()\n",
    "#         # generate target mask for decoder (can be reused as target sequences are padded to same length (probably?))\n",
    "#         self.target_mask = self.make_target_mask(longest_label)\n",
    "\n",
    "#         # convolutional block (5 convolutions)\n",
    "#         # first convolution\n",
    "#         self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 8, kernel_size = (3,3))\n",
    "#         width = input_width - 2\n",
    "#         height = input_height - 2\n",
    "#         self.leakyRelu = nn.LeakyReLU()     # reuse in later layers\n",
    "#         self.maxPool = nn.MaxPool2d((2,2))  # reuse in later layers\n",
    "#         width = int(np.floor(width/2))\n",
    "#         height = int(np.floor(height/2))\n",
    "#         self.layerNorm1 = nn.LayerNorm(normalized_shape = [8, height, width])\n",
    "#         self.dropout = nn.Dropout(0.2)      # reuse in later layers\n",
    "\n",
    "#         # second convolutional layer\n",
    "#         self.conv2 = nn.Conv2d(in_channels = 8, out_channels = 16, kernel_size = (3, 3))\n",
    "#         width -= 2\n",
    "#         height -= 2\n",
    "#         # after maxpool\n",
    "#         width = int(np.floor(width/2))\n",
    "#         height = int(np.floor(height/2))\n",
    "#         self.layerNorm2 = nn.LayerNorm(normalized_shape = [16, height, width])\n",
    "\n",
    "\n",
    "#         # third convolutional layer\n",
    "#         self.conv3 = nn.Conv2d(in_channels = 16, out_channels = 32, kernel_size = (3, 3))\n",
    "#         width -= 2\n",
    "#         height -= 2\n",
    "#         # after maxpool\n",
    "#         width = int(np.floor(width/2))\n",
    "#         height = int(np.floor(height/2))\n",
    "#         self.layerNorm3 = nn.LayerNorm(normalized_shape = [32, height, width])\n",
    "\n",
    "#         # forth convolutional layer\n",
    "#         self.conv4 = nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = (3, 3))\n",
    "#         width -= 2\n",
    "#         height -= 2\n",
    "#         # no maxpool\n",
    "#         self.layerNorm4 = nn.LayerNorm(normalized_shape = [64, height, width])\n",
    "\n",
    "#         # fifth convolutional layer (kernel size to better match shape of character)\n",
    "#         self.conv5 = nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size = (4, 2))\n",
    "#         width -= 1\n",
    "#         height -= 3\n",
    "#         # no maxpool\n",
    "#         self.layerNorm5 = nn.LayerNorm(normalized_shape = [128, height, width])\n",
    "\n",
    "#         # following is convolution with width 1 which is used to flatten the current output\n",
    "#         self.flattenConv = nn.Conv2d(in_channels = 128, out_channels = 128, kernel_size = (height, 1))\n",
    "#         # self.layerNorm6 = nn.LayerNorm(normalized_shape = [128, 1, width])\n",
    "\n",
    "#         # dense layer to upscale from 128 to 256\n",
    "#         self.dense1 = nn.Linear(in_features = 128, out_features = 256)\n",
    "#         # sinusoidal positional encoding is added to the output of the dense layer\n",
    "#         self.encoder_pos_encoding = SinPosEncoding(dimensionality = 256)\n",
    "\n",
    "#         # transformer encoder layers (4 stacked transformer encoder layers (4 headed attention))\n",
    "#         self.trans_encoder1 = nn.TransformerEncoderLayer(d_model = 256, nhead = 4, dim_feedforward = 1024, dropout = 0.2)\n",
    "#         self.trans_encoder2 = nn.TransformerEncoderLayer(d_model = 256, nhead = 4, dim_feedforward = 1024, dropout = 0.2)\n",
    "#         self.trans_encoder3 = nn.TransformerEncoderLayer(d_model = 256, nhead = 4, dim_feedforward = 1024, dropout = 0.2)\n",
    "#         self.trans_encoder4 = nn.TransformerEncoderLayer(d_model = 256, nhead = 4, dim_feedforward = 1024, dropout = 0.2)\n",
    "\n",
    "#         # dense layer for backprop CTC Loss of intermediate encoder result\n",
    "#         self.encoder_out_dense = nn.Linear(256, total_nr_of_tokens)\n",
    "\n",
    "#         # Here starts: decoder\n",
    "#         # character embedding (dim rule of thumb -> 4th sqrt of nr_embeddings: for ~80 = 3) \n",
    "#         #      NOTE: wrong, appearantly dims (encoder output, target embedding) need to be the same\n",
    "#         # <PAD> embedding idx = 0\n",
    "#         self.char_embedding = nn.Embedding(total_nr_of_tokens, 256, padding_idx = 0)\n",
    "#         # positional embedding of decoder input sequence\n",
    "#         self.decoder_pos_encoding = SinPosEncoding(dimensionality = 256)\n",
    "\n",
    "#         # transformer decoder layers (4 stacked transformer encoder layers (4 headed attention))\n",
    "#         self.trans_decoder1 = nn.TransformerDecoderLayer(d_model = 256, nhead = 4, dim_feedforward = 1024, dropout = 0.2)\n",
    "#         self.trans_decoder2 = nn.TransformerDecoderLayer(d_model = 256, nhead = 4, dim_feedforward = 1024, dropout = 0.2)\n",
    "#         self.trans_decoder3 = nn.TransformerDecoderLayer(d_model = 256, nhead = 4, dim_feedforward = 1024, dropout = 0.2)\n",
    "#         self.trans_decoder4 = nn.TransformerDecoderLayer(d_model = 256, nhead = 4, dim_feedforward = 1024, dropout = 0.2)\n",
    "\n",
    "#         self.decoder_out_dense = nn.Linear(256, total_nr_of_tokens)\n",
    "    \n",
    "#     # create a target mask for decoder input\n",
    "#     #   masks the future target characters from being seen by the model before they should\n",
    "#     def make_target_mask(self, size):\n",
    "#         mask = torch.zeros((size, size), dtype = torch.float32)\n",
    "        \n",
    "#         for i in range(size):\n",
    "#             for j in range(size):\n",
    "#                 if (j > i):\n",
    "#                     mask[i][j] = float('-inf')\n",
    "#         return mask\n",
    "    \n",
    "#     # first forward call: interm_outputs shoudl be a tensor with the embedding of <BOS>\n",
    "#     def forward(self, input_img, decoder_in_idxs):\n",
    "#         print(input_img.shape, decoder_in_idxs.shape)\n",
    "#         # through 5 convolutional layers\n",
    "#         # first conv\n",
    "#         print(\"start forward\")\n",
    "#         conv_out = self.layerNorm1(self.maxPool(self.leakyRelu(self.conv1(input_img))))\n",
    "#         conv_out = self.dropout(conv_out)\n",
    "#         # second conv\n",
    "#         conv_out = self.layerNorm2(self.maxPool(self.leakyRelu(self.conv2(conv_out))))\n",
    "#         conv_out = self.dropout(conv_out)\n",
    "#         # third conv\n",
    "#         conv_out = self.layerNorm3(self.maxPool(self.leakyRelu(self.conv3(conv_out))))\n",
    "#         conv_out = self.dropout(conv_out)\n",
    "#         # forth conv\n",
    "#         conv_out = self.layerNorm4(self.leakyRelu(self.conv4(conv_out)))\n",
    "#         # fifth conv\n",
    "#         conv_out = self.layerNorm5(self.leakyRelu(self.conv5(conv_out)))\n",
    "\n",
    "#         # flatten layer\n",
    "#         conv_out = self.layerNorm6(self.leakyRelu(self.flattenConv(conv_out)))\n",
    "\n",
    "#         # dense layer (activation function not mentioned in paper) \n",
    "#         # needs reshaped tensor where dims are reversed ((batch, 128, 1, x) -> (batch, x, 1, 128))\n",
    "#         conv_out = torch.reshape(conv_out, (conv_out.size(0), conv_out.size(3), conv_out.size(2), conv_out.size(1)))\n",
    "#         conv_out = self.dense1(conv_out)\n",
    "\n",
    "#         print(\"conv out succes\")\n",
    "\n",
    "#         # add sinusodial positional information\n",
    "#         # needs reshape (batch, seq_len, 1, 256) -> (seq_len, batch, 256)  \n",
    "#         conv_out = torch.reshape(conv_out, (conv_out.size(1), conv_out.size(0), conv_out.size(3)))\n",
    "#         encoder_in = self.encoder_pos_encoding(conv_out)\n",
    "#         encoder_in = conv_out\n",
    "\n",
    "#         print(\"pos encoding conv out succes\")\n",
    "#         print(encoder_in.shape)\n",
    "#         print(encoder_in.dtype)\n",
    "#         # encoder_out = encoder_out[:, 0, :]\n",
    "#         encoder_out = torch.reshape(encoder_out, (encoder_out.size(0), 1, encoder_out.size(1)))\n",
    "#         print(encoder_out.shape)\n",
    "        \n",
    "\n",
    "#         # transformer encoder layers\n",
    "#         encoder_out = self.trans_encoder1(conv_out)\n",
    "#         # encoder_out = self.trans_encoder1(encoder_in)\n",
    "#         encoder_out = self.trans_encoder2(encoder_out)\n",
    "#         encoder_out = self.trans_encoder3(encoder_out)\n",
    "#         encoder_out = self.trans_encoder4(encoder_out)\n",
    "\n",
    "#         print(\"encoder out succes\")\n",
    "\n",
    "#         # dense layer for intermediate output of decoder (CTC Loss)\n",
    "#         interm_encoder_out = self.encoder_out_dense(encoder_out)\n",
    "\n",
    "#         print(\"encoder dense out succes\")\n",
    "\n",
    "#         # add sinusodial positional information again\n",
    "#         encoder_out = self.encoder_pos_encoding(encoder_out)\n",
    "\n",
    "#         print(\"pos encoding encoder out succes\")\n",
    "#         # target sequence (shifted right (so with <BOS> token))\n",
    "#         # print(self.char_embedding)\n",
    "#         decoder_in = self.char_embedding(decoder_in_idxs)\n",
    "#         # sys.exit()\n",
    "        \n",
    "#         print(\"char embedding succes\")\n",
    "\n",
    "#         # add sinusoidal positional information to decoder input\n",
    "#         decoder_in = self.decoder_pos_encoding(decoder_in)\n",
    "        \n",
    "#         print(\"pos encoding decoder in succes\")\n",
    "\n",
    "#         # input encoder output and predicted chars into decoder\n",
    "#         decoder_out = self.trans_decoder1(decoder_in, encoder_out, self.target_mask)\n",
    "#         decoder_out = self.trans_decoder2(decoder_out, encoder_out, self.target_mask)\n",
    "#         decoder_out = self.trans_decoder3(decoder_out, encoder_out, self.target_mask)\n",
    "#         decoder_out = self.trans_decoder4(decoder_out, encoder_out, self.target_mask)\n",
    "\n",
    "#         print(\"decoder out succes\")\n",
    "\n",
    "#         # dense layer after decoder to predict one of all tokens (CE Loss)\n",
    "#         decoder_out = self.decoder_out_dense(decoder_out)\n",
    "\n",
    "#         print(\"decoder dense out succes\")\n",
    "#         return conv_out\n",
    "#         # return interm_encoder_out, decoder_out\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "hwr_transformer = HWRTransformer(INPUT_HEIGHT, input_width, len(char_to_idx_mapping), longest_label)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image tensor shape:\n",
      "-> torch.Size([1, 128, 2260])\n",
      "label as idxs shape:\n",
      "-> torch.Size([56])\n",
      "label as idxs reversed:\n",
      "-> ['p', 'r', 'o', '-', 'w', 'e', 's', 't', 'e', 'r', 'n', ' ', 'c', 'e', 'n', 't', 'r', 'e', ' ', 'a', 'n', 'd', ' ', 's', 'o', 'u', 't', 'h', '.', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "label length:\n",
      "-> 30\n",
      "one hot label shape:\n",
      "-> torch.Size([56, 1, 82])\n",
      "label shifted right embedding index tensor shape:\n",
      "-> torch.Size([56, 1])\n",
      "\n",
      "Shape of output of encoder (CTC Loss):\n",
      "-> torch.Size([277, 1, 82])\n",
      "Shape of decoder output (CE Loss):\n",
      "-> torch.Size([56, 1, 82])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test image as tensor, test label as one hot encoded target characters, labels shifted right as indices for embedding table\n",
    "image, label_as_idxs, label_length, test_label_one_hot, label_as_idxs_shifted_right = train_set[2]\n",
    "print(\"image tensor shape:\\n->\", image.shape)\n",
    "print(\"label as idxs shape:\\n->\", label_as_idxs.shape)\n",
    "print(\"label as idxs reversed:\\n->\", [train_set.idx_to_char_mapping[char.item()] for char in label_as_idxs])\n",
    "print(\"label length:\\n->\", label_length)\n",
    "print(\"one hot label shape:\\n->\", test_label_one_hot.shape)\n",
    "# torch.set_printoptions(threshold=10000)\n",
    "# print(test_label_one_hot)\n",
    "print(\"label shifted right embedding index tensor shape:\\n->\", label_as_idxs_shifted_right.shape)\n",
    "\n",
    "# create \"batch\" with single image\n",
    "test_image_batch = image.unsqueeze(0)\n",
    "labels_shifted_right_idxs_batch = label_as_idxs_shifted_right.unsqueeze(0)\n",
    "\n",
    "# plt.imshow(test_image_batch[0, 0, :, :], cmap = \"gray\")\n",
    "plt.imshow(image[0, :, :], cmap = \"gray\")\n",
    "\n",
    "# test label = <BOS> *sentence in tokens* <EOS> <PAD> <PAD> ... \n",
    "out1, out2 = hwr_transformer(test_image_batch, labels_shifted_right_idxs_batch)\n",
    "# out1 = hwr_transformer(test_image_batch, label_shifted_right_idxs)\n",
    "print(\"\\nShape of output of encoder (CTC Loss):\\n->\", out1.shape)\n",
    "print(\"Shape of decoder output (CE Loss):\\n->\", out2.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define hybrid loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridLoss(nn.Module):\n",
    "    def __init__(self, balance, nr_of_classes):\n",
    "        super(HybridLoss, self).__init__()\n",
    "        # allignment probabilities over encoded input sequence and target sequence\n",
    "        #   labels are in conform with char to idx mapping (nr of classes - 1 indices)\n",
    "        #   so I decided to make the blank index the next unused idx mapping\n",
    "        self.interm_CTCloss = nn.CTCLoss(blank = nr_of_classes)\n",
    "        # difference between decodeced input sequence and target sequence\n",
    "        self.output_CELoss = nn.CrossEntropyLoss()\n",
    "\n",
    "        # balance between CTC Loss and CE Loss (R: [0, 1])\n",
    "        if balance < 0 or balance > 1:\n",
    "            raise ValueError(\"Balance should be a value between 0 (only output CELoss) and 1 (only intermediate CTCLoss)\")\n",
    "        self.balance = balance\n",
    "\n",
    "    def setBalance(self, balance):\n",
    "        self.balance = balance\n",
    "\n",
    "    def forward(self, encoder_output, encoder_target, label_length, decoder_output, decoder_target):\n",
    "        input_length = encoder_output.size()\n",
    "        \n",
    "        interm_loss = self.interm_CTCloss(encoder_output, encoder_target)\n",
    "        output_loss = self.output_CELoss(decoder_output, decoder_target)\n",
    "        \n",
    "        return (self.balance * interm_loss + (1 - self.balance) * output_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82\n"
     ]
    }
   ],
   "source": [
    "# in the paper they only used balance to test efficiousness of the hybrid loss, \n",
    "#   and train with a balance of 0.5\n",
    "nr_of_classes = len(char_to_idx_mapping)\n",
    "print(nr_of_classes)\n",
    "hybrid_loss_func = HybridLoss(0.5, nr_of_classes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(hwr_transformer.parameters(), lr = 0.0001)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, test_loader, loss_func, optim, epochs):\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        running_loss_train = 0 \n",
    "        running_loss_test = 0\n",
    "        \n",
    "        # train\n",
    "        for i, data in enumerate(train_loader):\n",
    "            # batched inputs (encoder = images, decoder = labels_shifted_rigth) and labels\n",
    "            images, labels_as_idxs, labels_lengths, one_hot_labels, labels_as_idxs_shifted_right = data\n",
    "            # print(labels_as_idxs.shape)\n",
    "            \n",
    "            # zero gradients before any calculations\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # predict\n",
    "            interm_outputs, decoder_outputs = model(images, labels_as_idxs_shifted_right)\n",
    "            print(interm_outputs.shape)\n",
    "            \n",
    "            # TODO: calc loss \n",
    "            loss = loss_func(interm_outputs, labels_as_idxs, labels_lengths, decoder_outputs, one_hot_labels)\n",
    "            print(loss.item())\n",
    "            \n",
    "            # take step along loss gradients\n",
    "            optimizer.step()\n",
    "            \n",
    "            # add to running loss\n",
    "            running_loss_train += loss.item()\n",
    "        \n",
    "        # test\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(test_loader):\n",
    "                # batched inputs (encoder = images, decoder = labels_shifted_rigth) and labels\n",
    "                images, labels_as_idxs, labels_lengths, one_hot_labels, labels_as_idxs_shifted_right = data\n",
    "\n",
    "                \n",
    "                # predict\n",
    "                interm_outputs, decoder_outputs = model(images, labels_as_idxs_shifted_right)\n",
    "                \n",
    "                # TODO: calc loss \n",
    "                loss = loss_func(interm_outputs, labels_as_idxs, decoder_outputs, one_hot_labels)\n",
    "                \n",
    "                # add to running loss\n",
    "                running_loss_test += loss.item()\n",
    "            \n",
    "        # add to loss value lists\n",
    "        train_losses.append(running_loss_train / len(train_loader))\n",
    "        test_losses.append(running_loss_test / len(test_loader))\n",
    "\n",
    "        print(\"epoch:\", epoch, \"\\ntrain_loss:\", train_losses[-1], \"\\ntest_loss:\", test_losses[-1])\n",
    "        \n",
    "    # return train_losses, test_losses"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([277, 16, 82])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "forward() missing 2 required positional arguments: 'input_lengths' and 'target_lengths'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[170], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train(hwr_transformer, train_loader, test_loader, hybrid_loss_func, optimizer, EPOCHS)\n",
      "Cell \u001b[0;32mIn[169], line 23\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, test_loader, loss_func, optim, epochs)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39mprint\u001b[39m(interm_outputs\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     22\u001b[0m \u001b[39m# TODO: calc loss \u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m loss \u001b[39m=\u001b[39m loss_func(interm_outputs, labels_as_idxs, labels_lengths, decoder_outputs, one_hot_labels)\n\u001b[1;32m     24\u001b[0m \u001b[39mprint\u001b[39m(loss\u001b[39m.\u001b[39mitem())\n\u001b[1;32m     26\u001b[0m \u001b[39m# take step along loss gradients\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[166], line 22\u001b[0m, in \u001b[0;36mHybridLoss.forward\u001b[0;34m(self, encoder_output, encoder_target, label_length, decoder_output, decoder_target)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, encoder_output, encoder_target, label_length, decoder_output, decoder_target):\n\u001b[1;32m     20\u001b[0m     input_length \u001b[39m=\u001b[39m encoder_output\u001b[39m.\u001b[39msize()\n\u001b[0;32m---> 22\u001b[0m     interm_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minterm_CTCloss(encoder_output, encoder_target)\n\u001b[1;32m     23\u001b[0m     output_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_CELoss(decoder_output, decoder_target)\n\u001b[1;32m     25\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbalance \u001b[39m*\u001b[39m interm_loss \u001b[39m+\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbalance) \u001b[39m*\u001b[39m output_loss)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() missing 2 required positional arguments: 'input_lengths' and 'target_lengths'"
     ]
    }
   ],
   "source": [
    "train(hwr_transformer, train_loader, test_loader, hybrid_loss_func, optimizer, EPOCHS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
