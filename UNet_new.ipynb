{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fc3022d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from tensorflow.keras.metrics import MeanIoU\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from skimage import data\n",
    "from skimage.filters import threshold_otsu\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5be97be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_folder=r'C:\\Users\\16645\\Desktop\\HWR\\monkbrill2'\n",
    "\n",
    "def create_dataset(img_folder):\n",
    "    img_data_array = []\n",
    "    # training data    \n",
    "    \n",
    "    for dir1 in os.listdir(img_folder):\n",
    "        for file in os.listdir(os.path.join(img_folder, dir1)):            \n",
    "            #read the image\n",
    "            image_path= os.path.join(img_folder, dir1,  file)\n",
    "            image= cv2.imread(image_path, -1)\n",
    "            \n",
    "            # convert the gray image to RBG(3 channels), because we gonna to use the Unet to encode and decode it to a mask image\n",
    "            RGB_image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)\n",
    "            RGB_image = cv2.resize(RGB_image, (28,28))\n",
    "            RGB_image = RGB_image.reshape(28,28,3)\n",
    "            RGB_image = np.array(RGB_image)\n",
    "            img_data_array.append(RGB_image)\n",
    "            \n",
    "    return np.array(img_data_array)\n",
    "\n",
    "def create_mask_dataset(img_folder):      \n",
    "    class_name = []\n",
    "    class_color = []\n",
    "    # instance label and its corresponding colour\n",
    "    mask_img_data_array = []\n",
    "    # array of image Mask\n",
    "    \n",
    "    for dir1 in os.listdir(img_folder):\n",
    "        # set a specific color for each classes\n",
    "        color = np.array([random.randint(0,255),random.randint(0,255),random.randint(0,255)])\n",
    "        class_name.append(dir1)\n",
    "        class_color.append(color)\n",
    "\n",
    "        for file in os.listdir(os.path.join(img_folder, dir1)):\n",
    "            #read the image\n",
    "            image_path = os.path.join(img_folder, dir1,  file)\n",
    "            image = cv2.imread(image_path, -1)\n",
    "            image = cv2.resize(image, (28,28))\n",
    "            #srate to create the mask data set\n",
    "            height, width = image.shape[0:2]\n",
    "            thresh = 60\n",
    "            \n",
    "            # Convert the row image to a mask image, first convert it into a binary image\n",
    "            # iterate through each pixel\n",
    "            for row in range(height):\n",
    "                for col in range(width):\n",
    "                    # get the grayscale\n",
    "                    gray = image[row, col]\n",
    "                    # If the grayscale value is higher than the threshold, it is equal to the maximum value of 255\n",
    "                    if gray > thresh:\n",
    "                        image[row, col] = 255\n",
    "                    # If it is less than the threshold, it is directly changed to 0\n",
    "                    elif gray < thresh:\n",
    "                        image[row, col] = 0\n",
    "            thresh = threshold_otsu(image)\n",
    "            binary = image > thresh\n",
    "\n",
    "            # Make 3 channel RGB image same dimensions\n",
    "            RGB = np.zeros((binary.shape[0],binary.shape[1],3), dtype=np.uint8)\n",
    "\n",
    "            # Make True pixels red\n",
    "            RGB[binary]  = [255,255,255]\n",
    "            # Make False pixels blue\n",
    "            RGB[~binary] = color\n",
    "            color = np.array(color)\n",
    "            mask_img_data_array.append(RGB) \n",
    "            \n",
    "    return np.array(mask_img_data_array), np.array(class_name), np.array(class_color)\n",
    "\n",
    "\n",
    "# extract the image array and class name\n",
    "img_data = create_dataset(r'C:\\Users\\16645\\Desktop\\HWR\\monkbrill2')\n",
    "mask_data, class_name, class_color = create_mask_dataset(r'C:\\Users\\16645\\Desktop\\HWR\\monkbrill2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9ada569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5537, 28, 28, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_data.shape\n",
    "mask_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a088789f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generate the synthetic dataset\n",
    "random.randint(0, mask_data.shape[0] - 1)\n",
    "synthetic_img_data = []\n",
    "synthetic_mask_data = []\n",
    "\n",
    "for i in range(5000):\n",
    "    a = random.randint(0, mask_data.shape[0] - 1)\n",
    "    b = random.randint(0, mask_data.shape[0] - 1)\n",
    "    c = random.randint(0, mask_data.shape[0] - 1)\n",
    "    d = random.randint(0, mask_data.shape[0] - 1)\n",
    "    e = random.randint(0, mask_data.shape[0] - 1)\n",
    "    f = random.randint(0, mask_data.shape[0] - 1)\n",
    "    g = random.randint(0, mask_data.shape[0] - 1)\n",
    "    synthetic_img = np.concatenate([img_data[a],img_data[b],img_data[c],img_data[d],img_data[e],img_data[f],img_data[g]], axis=1)  # axis=0纵向  axis=1横向\n",
    "    synthetic_mask = np.concatenate([mask_data[a],mask_data[b],mask_data[c],mask_data[d],mask_data[e],mask_data[f],mask_data[g]], axis=1)  # axis=0纵向  axis=1横向\n",
    "    synthetic_img_data.append(synthetic_img)\n",
    "    synthetic_mask_data.append(synthetic_mask)\n",
    "    \n",
    "cv2.imshow('img', synthetic_mask_data[0])\n",
    "cv2.waitKey()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2cafb4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow('img', synthetic_img_data[0])\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdaaae3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 28, 196, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthetic_img_data = np.array(synthetic_img_data)\n",
    "synthetic_mask_data = np.array(synthetic_mask_data)\n",
    "synthetic_mask_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c42dce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 28, 196, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Give every color a category, the background is 0 and the classes is from 1 to 27\n",
    "\n",
    "label = synthetic_mask_data\n",
    "labels = []\n",
    "\n",
    "def flatLabels(label):\n",
    "    label_seg = np.zeros(label.shape, dtype=np.uint8)\n",
    "    label_seg[np.all(label == [255,255,255] , axis=-1)] = 0\n",
    "    for i in range(27):\n",
    "        label_seg[np.all(label == class_color[i] , axis=-1)] = i+1\n",
    "    label_seg = label_seg[:, :, 0]\n",
    "    return label_seg\n",
    "\n",
    "\n",
    "for i in range(synthetic_mask_data.shape[0]):\n",
    "    signal_label = flatLabels(synthetic_mask_data[i])\n",
    "    labels.append(signal_label)\n",
    "\n",
    "labels = np.array(labels)\n",
    "labels = np.expand_dims(labels, axis=3)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82997117",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5000, 28, 196, 28)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#one hot encoding to_categorical\n",
    "n_classes = 28\n",
    "from keras.utils import to_categorical\n",
    "labels_cat = to_categorical(labels, num_classes=n_classes)\n",
    "labels_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a43bb9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(synthetic_img_data, labels_cat, test_size = 0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "df042bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 28, 196, 3)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 28, 196, 16)  448         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 28, 196, 16)  2320        conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 14, 98, 16)   0           conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 14, 98, 32)   4640        max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 14, 98, 32)   9248        conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 7, 49, 32)    0           conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 7, 49, 64)    18496       max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 7, 49, 64)    36928       conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_6 (UpSampling2D)  (None, 14, 98, 64)   0           conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 14, 98, 32)   8224        up_sampling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 14, 98, 64)   0           conv2d_42[0][0]                  \n",
      "                                                                 conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 14, 98, 32)   18464       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 14, 98, 32)   9248        conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_7 (UpSampling2D)  (None, 28, 196, 32)  0           conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 28, 196, 16)  2064        up_sampling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 28, 196, 32)  0           conv2d_40[0][0]                  \n",
      "                                                                 conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 28, 196, 16)  4624        concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 28, 196, 16)  2320        conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 28, 196, 28)  476         conv2d_50[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 117,500\n",
      "Trainable params: 117,500\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Dropout, UpSampling2D, concatenate\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import categorical_crossentropy\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Dropout, UpSampling2D, concatenate\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import categorical_crossentropy\n",
    "import keras_metrics\n",
    "\n",
    "def UNet(num_classes=28):\n",
    "    # Input layer\n",
    "    inputs = Input((28, 196, 3))\n",
    "    \n",
    "    # Encoder\n",
    "    conv1 = Conv2D(16, 3, activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(16, 3, activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    \n",
    "    conv2 = Conv2D(32, 3, activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(32, 3, activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    \n",
    "    \n",
    "    # Bridge\n",
    "    conv4 = Conv2D(64, 3, activation='relu', padding='same')(pool2)\n",
    "    conv4 = Conv2D(64, 3, activation='relu', padding='same')(conv4)\n",
    "    \n",
    "    # Decoder\n",
    "    up5 = UpSampling2D(size=(2, 2))(conv4)\n",
    "    up5 = Conv2D(32, 2, activation='relu', padding='same')(up5)\n",
    "    \n",
    "    merge5 = concatenate([conv2, up5], axis=3)\n",
    "    conv5 = Conv2D(32, 3, activation='relu', padding='same')(merge5)\n",
    "    conv5 = Conv2D(32, 3, activation='relu', padding='same')(conv5)\n",
    "    \n",
    "    up6 = UpSampling2D(size=(2, 2))(conv5)\n",
    "    up6 = Conv2D(16, 2, activation='relu', padding='same')(up6)\n",
    "    merge6 = concatenate([conv1, up6], axis=3)\n",
    "    conv6 = Conv2D(16, 3, activation='relu', padding='same')(merge6)\n",
    "    conv6 = Conv2D(16, 3, activation='relu', padding='same')(conv6)\n",
    "    \n",
    "    \n",
    "    # Output layer\n",
    "    output = Conv2D(num_classes, 1, activation='softmax')(conv6)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# Create the UNet model\n",
    "model = UNet(num_classes=28)\n",
    "model.summary()\n",
    "model.compile(optimizer=Adam(lr=0.1), loss=categorical_crossentropy, metrics=[keras_metrics.f1_score()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d496cb8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "WARNING:tensorflow:From c:\\users\\16645\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras_metrics\\metrics.py:51: calling Layer.add_update (from tensorflow.python.keras.engine.base_layer) with inputs is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`inputs` is now automatically inferred\n",
      "WARNING:tensorflow:From c:\\users\\16645\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras_metrics\\metrics.py:26: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "282/282 [==============================] - 69s 246ms/step - loss: 15.7958 - f1_score: 0.0000e+00 - val_loss: 15.8163 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/2\n",
      "282/282 [==============================] - 74s 263ms/step - loss: 15.7981 - f1_score: 0.0000e+00 - val_loss: 15.8163 - val_f1_score: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size = 16,\n",
    "                    verbose=1,\n",
    "                    epochs=2,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a87b4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = r'C:\\Users\\16645\\Desktop\\HWR\\1.jpg'\n",
    "img = cv2.imread(img,-1)\n",
    "img = np.array(img)\n",
    "img = cv2.cvtColor(img,cv2.COLOR_GRAY2RGB)\n",
    "img = cv2.resize(img,(28,196))\n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey()\n",
    "img = img.reshape(1,28,196,3)\n",
    "img = np.array(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "42936c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = model.predict(img)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cb2c1719",
   "metadata": {},
   "outputs": [],
   "source": [
    "def de_one_hot(one_hot):\n",
    "    de_onehot = []\n",
    "    for i in range(len(one_hot)):\n",
    "        for j in range(28):\n",
    "            if one_hot[i][j] == 1:\n",
    "                de_onehot.append(j)\n",
    "    return de_onehot\n",
    "\n",
    "\n",
    "pre_1 = []\n",
    "for i in range(28):\n",
    "    pre_1.append(de_one_hot(pre[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0600af5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
